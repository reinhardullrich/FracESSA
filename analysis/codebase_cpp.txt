=== cpp/CMakeLists.txt ===
cmake_minimum_required(VERSION 3.14)

project(fracessa
    VERSION 1.0.0
    DESCRIPTION "FRACESSA - Fractional ESS Analyzer"
    LANGUAGES CXX C
)

# ==============================================================================
# 1. Compiler Settings
# ==============================================================================
set(CMAKE_CXX_STANDARD 17)
set(CMAKE_CXX_STANDARD_REQUIRED ON)
set(CMAKE_CXX_EXTENSIONS OFF)

if(MSVC)
    # Windows: VCPKG static triplet handles /MT (static runtime) automatically
    add_compile_options(/O2 /Oi /Ot /GL /fp:fast /DNDEBUG)
    add_link_options(/LTCG)
else()
    # Linux/Mac: Optimization flags
    add_compile_options(-O3 -march=native -flto -funroll-loops -DNDEBUG)
    
    # Linux: Link standard C++ libraries statically for maximum portability
    # This ensures the binary runs on older Linux distros without "GLIBCXX not found" errors
    if(CMAKE_SYSTEM_NAME STREQUAL "Linux")
        add_link_options(-static-libgcc -static-libstdc++)
    endif()

    include(CheckIPOSupported)
    check_ipo_supported(RESULT IPO_SUPPORTED)
    if(IPO_SUPPORTED)
        set(CMAKE_INTERPROCEDURAL_OPTIMIZATION TRUE)
    endif()
endif()

# ==============================================================================
# 2. Dependencies (spdlog, argparse)
# ==============================================================================
include(FetchContent)

FetchContent_Declare(spdlog
    GIT_REPOSITORY https://github.com/gabime/spdlog.git
    GIT_TAG v1.13.0
)
FetchContent_Declare(argparse
    GIT_REPOSITORY https://github.com/p-ranav/argparse.git
    GIT_TAG v2.9
)
FetchContent_MakeAvailable(spdlog argparse)

# ==============================================================================
# 3. Math Dependencies (GMP, MPFR, FLINT)
# ==============================================================================

# --- GMP & MPFR (Linux/Mac Only) ---
# Windows handles this via vcpkg
if(NOT WIN32)
    # FORCE STATIC linking on Linux/Mac by looking for .a files only
    set(_ORIG_CMAKE_FIND_LIBRARY_SUFFIXES ${CMAKE_FIND_LIBRARY_SUFFIXES})
    set(CMAKE_FIND_LIBRARY_SUFFIXES ".a")
    
    find_library(GMP_LIB NAMES gmp libgmp mpir)
    find_path(GMP_INCLUDE_DIR NAMES gmp.h)

    find_library(MPFR_LIB NAMES mpfr libmpfr)
    find_path(MPFR_INCLUDE_DIR NAMES mpfr.h)

    # Restore original suffixes so other things don't break
    set(CMAKE_FIND_LIBRARY_SUFFIXES ${_ORIG_CMAKE_FIND_LIBRARY_SUFFIXES})

    if(NOT (GMP_LIB AND GMP_INCLUDE_DIR))
        message(FATAL_ERROR "GMP static lib not found.")
    endif()

    if(NOT (MPFR_LIB AND MPFR_INCLUDE_DIR))
        message(FATAL_ERROR "MPFR static lib not found.")
    endif()
endif()

# --- FLINT ---
set(FLINT_INCLUDE_DIRS "")
set(FLINT_LIBRARIES "")

if(WIN32)
    # WINDOWS: Use vcpkg provided libraries
    find_library(FLINT_LIB NAMES flint libflint)
    find_path(FLINT_INCLUDE_DIR NAMES flint/flint.h)
    
    if(FLINT_LIB AND FLINT_INCLUDE_DIR)
        set(FLINT_LIBRARIES ${FLINT_LIB})
        set(FLINT_INCLUDE_DIRS ${FLINT_INCLUDE_DIR})
        message(STATUS "Found FLINT (Windows): ${FLINT_LIB}")
    else()
        message(FATAL_ERROR "FLINT not found. Ensure 'vcpkg install flint:x64-windows-static' ran.")
    endif()
else()
    # LINUX / MACOS: Build FLINT from Source (Tarball)
    # This ensures we get a static .a file linked into our binary
    include(ExternalProject)
    
    get_filename_component(GMP_LIB_DIR ${GMP_LIB} DIRECTORY)
    get_filename_component(MPFR_LIB_DIR ${MPFR_LIB} DIRECTORY)

    ExternalProject_Add(flint_build
        URL https://github.com/flintlib/flint/releases/download/v3.0.1/flint-3.0.1.tar.gz
        PREFIX ${CMAKE_BINARY_DIR}/third_party/flint
        BUILD_IN_SOURCE 1
        # Configure FLINT to use the system's (static) GMP/MPFR
        CONFIGURE_COMMAND ./configure 
            --prefix=<INSTALL_DIR> 
            --with-gmp=${GMP_LIB_DIR}/.. 
            --with-mpfr=${MPFR_LIB_DIR}/..
            --disable-shared 
            --enable-static
        BUILD_COMMAND make -j4
        INSTALL_COMMAND make install
    )

    ExternalProject_Get_Property(flint_build INSTALL_DIR)
    set(FLINT_INCLUDE_DIRS ${INSTALL_DIR}/include)
    set(FLINT_LIBRARIES ${INSTALL_DIR}/lib/libflint.a)
endif()

# ==============================================================================
# 4. Build Targets
# ==============================================================================

add_library(fracessa_lib
    src/fracessa.cpp
    src/findeq.cpp
    src/checkstab.cpp
)

target_include_directories(fracessa_lib PUBLIC
    $<BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/include>
    $<BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/include/fracessa>
    ${FLINT_INCLUDE_DIRS}
    ${GMP_INCLUDE_DIR}
    ${MPFR_INCLUDE_DIR}
)

target_link_libraries(fracessa_lib PUBLIC
    spdlog::spdlog
    ${FLINT_LIBRARIES}
    ${MPFR_LIB}
    ${GMP_LIB}
)

if(NOT WIN32)
    add_dependencies(fracessa_lib flint_build)
    find_package(Threads REQUIRED)
    target_link_libraries(fracessa_lib PUBLIC Threads::Threads)
endif()

add_executable(fracessa src/main.cpp)

target_link_libraries(fracessa PRIVATE
    fracessa_lib
    argparse::argparse
)

install(TARGETS fracessa RUNTIME DESTINATION bin)
=== .github/workflows/release.yml ===
name: Release Fracessa

on:
  push:
    tags:
      - 'v*'

permissions:
  contents: write

jobs:
  build:
    name: Build on ${{ matrix.os }}
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-22.04, macos-latest, windows-latest]

    steps:
    - uses: actions/checkout@v3

    # --- CACHE VCPKG (Windows Only) ---
    - name: Restore vcpkg cache
      if: runner.os == 'Windows'
      uses: actions/cache@v3
      with:
        path: C:/vcpkg/installed
        # New cache key for the release-only build
        key: ${{ runner.os }}-vcpkg-flint-static-release-v1
        restore-keys: |
          ${{ runner.os }}-vcpkg-

    # --- DEPENDENCIES ---
    - name: Install Dependencies (Linux)
      if: runner.os == 'Linux'
      run: |
        sudo apt-get update
        sudo apt-get install -y libgmp-dev libmpfr-dev

    - name: Install Dependencies (macOS)
      if: runner.os == 'macOS'
      run: |
        brew install gmp mpfr

    # --- WINDOWS SETUP (Optimized) ---
    - name: Install Dependencies (Windows)
      if: runner.os == 'Windows'
      shell: bash
      run: |
        # 1. Create a custom triplet that disables Debug builds
        mkdir -p triplets
        cat <<EOF > triplets/x64-windows-static-release.cmake
        set(VCPKG_TARGET_ARCHITECTURE x64)
        set(VCPKG_CRT_LINKAGE static)
        set(VCPKG_LIBRARY_LINKAGE static)
        set(VCPKG_BUILD_TYPE release)
        EOF

        # 2. Install FLINT using this release-only triplet
        # This prevents building the 'dbg' version, cutting build time in half.
        vcpkg install flint:x64-windows-static-release --overlay-triplets=triplets
        vcpkg integrate install

    # --- CONFIGURE ---
    - name: Configure CMake
      run: >
        cmake -B build -S cpp
        -DCMAKE_BUILD_TYPE=Release
        ${{ runner.os == 'Windows' && '-DCMAKE_TOOLCHAIN_FILE=C:/vcpkg/scripts/buildsystems/vcpkg.cmake -DVCPKG_TARGET_TRIPLET=x64-windows-static-release -DVCPKG_OVERLAY_TRIPLETS=triplets' || '' }}

    # --- BUILD ---
    - name: Build
      run: cmake --build build --config Release -j 4

    # --- STRIP BINARIES ---
    - name: Strip Binary (Linux/Mac)
      if: runner.os != 'Windows'
      run: strip build/fracessa

    # --- PREPARE ARTIFACTS ---
    - name: Rename Binary (Linux)
      if: runner.os == 'Linux'
      run: mv build/fracessa fracessa-linux

    - name: Rename Binary (macOS)
      if: runner.os == 'macOS'
      run: mv build/fracessa fracessa-macos

    - name: Rename Binary (Windows)
      if: runner.os == 'Windows'
      run: mv build/Release/fracessa.exe fracessa-windows.exe

    # --- UPLOAD TO STAGING ---
    - name: Upload Artifact
      uses: actions/upload-artifact@v4
      with:
        name: binary-${{ matrix.os }}
        path: fracessa-*
        if-no-files-found: error

  # --- PUBLISH RELEASE ---
  publish:
    needs: build
    runs-on: ubuntu-latest
    
    steps:
    - name: Download All Artifacts
      uses: actions/download-artifact@v4
      with:
        pattern: binary-*
        merge-multiple: true

    - name: Create GitHub Release
      uses: softprops/action-gh-release@v1
      with:
        files: |
          fracessa-linux
          fracessa-macos
          fracessa-windows.exe
        draft: false
        prerelease: false
        generate_release_notes: true
=== cpp/include/fracessa/bitset64.hpp ===
// bitset64.hpp
#pragma once

#include <cstdint>
#include <string>
#include <cstddef>

// Platform-specific intrinsics
#ifdef _MSC_VER
  #include <intrin.h>
#endif

// Portable popcount wrapper
inline size_t popcount64(uint64_t x) noexcept {
  #ifdef _MSC_VER
    return static_cast<size_t>(_mm_popcnt_u64(x));
  #else
    return static_cast<size_t>(__builtin_popcountll(x));
  #endif
}

// Portable count trailing zeros wrapper
inline size_t ctz64(uint64_t x) noexcept {
  #ifdef _MSC_VER
    unsigned long index;
    if (_BitScanForward64(&index, x)) {
      return static_cast<size_t>(index);
    }
    return 64; // undefined behavior case, but we check for 0 before calling
  #else
    return static_cast<size_t>(__builtin_ctzll(x));
  #endif
}

/// Ultra-optimized bitset for n <= 64.
/// - stores only uint64_t bits (8 bytes, same as uint64_t)
/// - nbits must be provided by caller when needed for masking
/// - all operations are inlined and branch-light
/// - NO bounds checks for maximum performance

// Type alias: bitset64 is just uint64_t
typedef uint64_t bitset64;

// Namespace for bitset64 operations
namespace bs64 {

inline bitset64 two_to_the_power_of(size_t n) noexcept {
  return 1ULL << n;
}

inline bitset64 set_bit_at_pos(bitset64 bits, size_t pos) noexcept {
  return bits | (1ULL << pos);
}

inline bitset64 clear_bit_at_pos(bitset64 bits, size_t pos) noexcept {
  return bits & ~(1ULL << pos);
}

inline bitset64 set_all_n_bits(size_t n) noexcept {
  return (1ULL << n) - 1ULL; //careful with n == 0
}

// circular rotate right by exactly 1 bit for a bitmask of size nbits
inline bitset64 rot_one_right(bitset64 bits, size_t n) noexcept {
  bitset64 mask = set_all_n_bits(n);
  bitset64 low = bits & mask;
  bitset64 lo = low << (n - 1);
  bitset64 hi = low >> 1;
  return (hi | lo) & mask;
}

inline bool is_set_at_pos(bitset64 bits, size_t pos) noexcept {
  return (bits >> pos) & 1ULL;
}

inline size_t count_set_bits(bitset64 bits) noexcept {
  return popcount64(bits);
}

inline size_t find_pos_first_set_bit(bitset64 bits) noexcept {
  return ctz64(bits);
}

// find next bit after pos
inline size_t find_pos_next_set_bit(bitset64 bits, size_t pos) noexcept {
  size_t p = pos + 1;
  uint64_t w = bits & (~0ULL << p);  // zero below p
  if (w) return ctz64(w);
  return static_cast<size_t>(64);  // no more bits found
}

// this ⊆ o <=> (this & ~o) == 0
inline bool is_subset_of(bitset64 bits, bitset64 o) noexcept {
  return (bits & ~o) == 0ULL;
}

// Return this \ o (set difference)
inline bitset64 subtract(bitset64 bits, bitset64 o) noexcept {
  return bits & ~o;
}

// Get a single-bit bitset64 with only the bit at position pos set
inline bitset64 single_bit_at_pos(size_t pos) noexcept {
  return 1ULL << pos;
}

// Get the lowest set bit as a bitset64 (only that bit is set, all other bits are 0)
inline bitset64 lowest_set_bit_as_bit(bitset64 bits) noexcept {
  size_t pos = find_pos_first_set_bit(bits);
  return single_bit_at_pos(pos);
}

// Get all set bits in bits that are before position pos
inline bitset64 bits_before_pos(bitset64 bits, size_t pos) noexcept {
  return bits & ((1ULL << pos) - 1);
}

//careful! no check for the biggest element here! done outside!
inline bitset64 next_bitset_with_same_popcount(bitset64 bits) noexcept {
  uint64_t t = bits | (bits - 1);
  return (t + 1) | (((~t & -~t) - 1) >> (ctz64(bits) + 1));
}

// Check if this bitset is in its smallest representation (canonical form)
// Uses early exit: returns false immediately if any rotation is smaller than original
// Optimized version: reduces masking operations for better performance
inline bool is_smallest_representation(bitset64 bits, size_t n) noexcept {
  uint64_t mask = set_all_n_bits(n);
  uint64_t original = bits & mask;
  uint64_t current = original;
  size_t shift_left = n - 1;
  
  for (size_t i = 1; i < n; i++) {
    current = ((current >> 1) | (current << shift_left)) & mask;
    if (current < original) {
      return false; //there exists a smaller representation, ie. this one cannot be canonical!
    }
  }
  // All rotations are >= original, so it's canonical
  return true;
}

// Convert to bitstring representation (MSB first, like std::bitset::to_string())
// Only outputs bits 0 to dimension-1 (rightmost dimension bits)
// Example: dimension=5, bits 0,3,4 set -> "10011"
inline std::string to_bitstring(bitset64 bits, size_t dimension) noexcept {
  if (dimension == 0) return "";
  
  std::string result;
  result.reserve(dimension);
  
  // Output from highest bit (dimension-1) to lowest bit (0)
  for (int i = static_cast<int>(dimension) - 1; i >= 0; i--) {
    result += (is_set_at_pos(bits, static_cast<size_t>(i)) ? '1' : '0');
  }
  
  return result;
}

// Convert to string representation (decimal representation of uint64)
inline std::string to_string(bitset64 bits) noexcept {
  return std::to_string(bits);
}

// portable hash (fast) **MurmurHash3 finalizer**
inline std::size_t hash(bitset64 bits) noexcept {
  // 64-bit mix (FNV-like)
  uint64_t x = bits;
  x ^= x >> 33;
  x *= 0xff51afd7ed558ccdULL;
  x ^= x >> 33;
  x *= 0xc4ceb9fe1a85ec53ULL;
  x ^= x >> 33;
  return static_cast<std::size_t>(x);
}

} // namespace bs64
=== cpp/include/fracessa/candidate.hpp ===
#ifndef CANDIDATE_H
#define CANDIDATE_H

#include <rational_linalg/matrix.hpp>
#include <fracessa/bitset64.hpp>
#include <string>
#include <sstream>
#include <iomanip>

class candidate
{
    public:
        size_t candidate_id = 0;
        rational_linalg::Matrix<fraction> vector;  // Column vector: Matrix<fraction>(n, 1) - always use arbitrary precision
        bitset64 support;
        size_t support_size = 0;
        bitset64 extended_support;
        size_t extended_support_size;
        size_t shift_reference;
        bool is_ess;
        std::string stability;
        fraction payoff;  // Always use arbitrary precision
        double payoff_double;

        std::string to_string() const
        {
            std::ostringstream oss;
            oss << candidate_id << ";";
            for (size_t i = 0; i < vector.rows(); i++) {
                oss << vector(i, 0);  // Uses optimized operator<<, no string allocation
                if (i < vector.rows() - 1) {
                    oss << ",";
                }
            }
            oss << ";" << bs64::to_string(support) << ";"
                << support_size << ";"
                << bs64::to_string(extended_support) << ";"
                << extended_support_size << ";"
                << shift_reference << ";"
                << is_ess << ";"
                << stability << ";"
                << payoff << ";"  // Uses optimized operator<<, no string allocation
                << std::fixed << std::setprecision(6) << payoff_double;
            return oss.str();
        }

        static std::string header()
        {
            return "candidate_id;vector;support;support_size;extended_support;extended_support_size;shift_reference;is_ess;stability;payoff;payoff_double;";
        }
};

#endif // CANDIDATE_H

=== cpp/include/fracessa/fracessa.hpp ===
// Migrated header for modern include path
#include <vector>
#include <string>
#include <memory>

#include <spdlog/spdlog.h>
#include <spdlog/sinks/rotating_file_sink.h>

#include <rational_linalg/matrix.hpp>
#include <fracessa/candidate.hpp>
#include <fracessa/bitset64.hpp>
#include <fracessa/supports.hpp>
#include <fracessa/matrix_server.hpp>


class fracessa
{
    public:

        fracessa(const rational_linalg::Matrix<fraction>& matrix, bool is_cs, bool with_candidates = false, bool exact = false, bool full_support = false, bool with_log = false, int matrix_id = -1);

        size_t ess_count_ = 0;
        std::vector<candidate> candidates_;

    private:

        // Matrix server handles all game/augmented/bee matrices and their operations
        MatrixServer matrix_server_;

        size_t dimension_;
        bool is_cs_;
        int matrix_id_;

        bool conf_with_candidates_;
        bool conf_exact_;
        bool conf_full_support_;
        bool conf_with_log_;

        
        candidate candidate_;

        Supports supports_;
        std::vector<bitset64> supports_to_remove_;  // Collect supports for batch removal

        std::shared_ptr<spdlog::logger> logger_;

        void search_one_support(const bitset64& support, size_t support_size, bool is_cs_and_coprime = false);
        
        // Templated function for all types (double, fraction)
        template<typename T>
        bool find_candidate(const bitset64& support, size_t support_size);
        
        // check_stability function for fraction
        void check_stability();

};


=== cpp/include/fracessa/matrix_server.hpp ===
#ifndef MATRIX_SERVER_HPP
#define MATRIX_SERVER_HPP

#include <rational_linalg/matrix.hpp>
#include <fracessa/bitset64.hpp>

/**
 * MatrixServer - Centralized matrix storage and operations for fracessa
 * 
 * This class manages all matrix representations (fraction, double)
 * and provides the matrix-building functionality needed by find_candidate and check_stability.
 */
class MatrixServer {
public:
    /**
     * Constructor - initializes all matrix representations from the input game matrix
     * @param game_matrix The input game matrix (fraction - FLINT fraction)
     */
    MatrixServer(const rational_linalg::Matrix<fraction>& game_matrix)
        : game_rational_(game_matrix)
    {
        // Always create game_double matrix (faster than checking every time)
        game_double_ = game_rational_.to_double();
        dimension_ = game_matrix.rows();
    }

    // =========================================================================
    // Public API - Get matrices as needed
    // =========================================================================


    template<typename T>
    rational_linalg::Matrix<T>& get_linear_system(const bitset64& support, size_t support_size) {
        auto& Ab = get_augmented<T>();
        const auto& game = get_game<T>();
        
        // Resize if needed (constructor zero-initializes)
        if (Ab.rows() != support_size + 1) {
            Ab = rational_linalg::Matrix<T>(support_size + 1, support_size + 2);
        }

        // Fill all rows in one pass
        size_t ab_row = 0;
        for (size_t i = 0; i < dimension_; ++i) {
            if (bs64::is_set_at_pos(support, i)) {
                // Fill submatrix columns (0 to support_size-1) from game_matrix
                size_t ab_col = 0;
                for (size_t j = 0; j < dimension_; ++j) {
                    if (bs64::is_set_at_pos(support, j)) {
                        Ab(ab_row, ab_col) = game(i, j);
                        ab_col++;
                    }
                }
                // Column support_size: -1 (last column of A)
                Ab(ab_row, support_size) = T(-1);
                // Column support_size + 1: 0 (b vector, initially zero)
                Ab(ab_row, support_size + 1) = T(0);
                ab_row++;
            }
        }
        
        // Fill last row: all 1s in columns 0..support_size-1, 0 in column support_size, 1 in column n
        for (size_t i = 0; i < support_size; ++i) {
            Ab(support_size, i) = T(1);
        }
        Ab(support_size, support_size) = T(0);      // Column support_size (last column of A)
        Ab(support_size, support_size + 1) = T(1);  // Column support_size + 1 (b vector, last element is 1)
        
        return Ab;
    }

    template<typename T>
    rational_linalg::Matrix<T>& get_bee_matrix(const bitset64& extended_support_reduced, size_t m) {
        auto& Bee = get_bee<T>();
        const auto& game = get_game<T>();
        
        size_t extended_support_size_reduced = bs64::count_set_bits(extended_support_reduced);
        
        // Resize if needed (constructor zero-initializes)
        if (Bee.rows() != extended_support_size_reduced) {
            Bee = rational_linalg::Matrix<T>(extended_support_size_reduced, extended_support_size_reduced);
        }

        size_t row = 0;
        size_t column = 0;
        for (size_t i = 0; i < dimension_; i++) {
            if (bs64::is_set_at_pos(extended_support_reduced, i)) {
                column = 0;
                for (size_t j = 0; j < i + 1; j++) {
                    if (bs64::is_set_at_pos(extended_support_reduced, j)) {
                        // Bee formula from Bomze 1992
                        Bee(row, column) = Bee(column, row) = 
                            game(m, j) + game(j, m) + game(i, m) + game(m, i) -
                            game(i, j) - game(j, i) - T(2) * game(m, m);
                        column += 1;
                    }
                }
                row += 1;
            }
        }
        
        return Bee;
    }

    template<typename T>
    const rational_linalg::Matrix<T>& get_game_matrix() const noexcept {
        return get_game<T>();
    }

private:
    // =========================================================================
    // Internal Helpers
    // =========================================================================
    
    /**
     * Get the appropriate game matrix for the template type
     */
    template<typename T>
    const rational_linalg::Matrix<T>& get_game() const noexcept {
        if constexpr (std::is_same_v<T, double>) {
            return game_double_;
        } else {
            return game_rational_;
        }
    }
    
    /**
     * Get the appropriate augmented matrix reference
     */
    template<typename T>
    rational_linalg::Matrix<T>& get_augmented() noexcept {
        if constexpr (std::is_same_v<T, double>) {
            return subgame_augmented_double_;
        } else {
            return subgame_augmented_rational_;
        }
    }
    
    /**
     * Get the appropriate Bee matrix reference
     */
    template<typename T>
    rational_linalg::Matrix<T>& get_bee() noexcept {
        if constexpr (std::is_same_v<T, double>) {
            return bee_double_;
        } else {
            return bee_rational_;
        }
    }
    

    // =========================================================================
    // Member Variables
    // =========================================================================
    
    // Game matrices
    rational_linalg::Matrix<fraction> game_rational_;
    rational_linalg::Matrix<double> game_double_;
    
    // Augmented matrices for linear solver (KKT system)
    rational_linalg::Matrix<double> subgame_augmented_double_;
    rational_linalg::Matrix<fraction> subgame_augmented_rational_;
    
    // Bee matrices for copositivity check
    rational_linalg::Matrix<fraction> bee_rational_;
    rational_linalg::Matrix<double> bee_double_;
    
    // State

    size_t dimension_;
};

#endif // MATRIX_SERVER_HPP


=== cpp/include/fracessa/supports.hpp ===
// supports.hpp
#pragma once
#include <cstddef>
#include <cstdint>
#include <vector>
#include <algorithm>
#include <numeric>
#include <fracessa/bitset64.hpp>

// Force-inline hint (same as bitset64.hpp)
#if defined(_MSC_VER)
#  define FORCE_INLINE __forceinline
#else
#  define FORCE_INLINE __attribute__((always_inline)) inline
#endif

/// Compute binomial coefficient C(n,k) = n!/(k!(n-k)!)
/// Returns uint64_t - safe since n <= 64, no overflow possible
/// No safety checks needed per user requirement
inline uint64_t binomial_coefficient(uint64_t n, uint64_t k) {
    if (k > n) return 0;
    if (k == 0 || k == n) return 1;
    if (k > n - k) k = n - k; // Use symmetry
    
    uint64_t result = 1;
    for (uint64_t i = 0; i < k; ++i) {
        result = result * (n - i) / (i + 1);
    }
    return result;
}

/// High-performance Supports class for managing support sets
/// All hot-path methods are FORCE_INLINE for maximum performance
class Supports {
private:
    std::vector<std::vector<bitset64>> supports_;
    size_t dimension_;
    bool is_cs_;
    
public:
    /// Constructor - stores parameters, does not initialize supports
    inline Supports(size_t dimension, bool is_cs) noexcept
        : supports_(dimension)
        , dimension_(dimension)
        , is_cs_(is_cs)
    {}
    
    /// Initialize all supports - must be called after construction
    inline void initialize() {
        // Reserve space for each support size using binomial coefficients and set coprime flags
        std::vector<bool> is_coprime(dimension_);
        for (size_t i = 0; i < dimension_; ++i) {
            supports_[i].reserve(binomial_coefficient(dimension_, i + 1));            
            if (is_cs_) 
                    is_coprime[i] = (std::gcd(i+1, dimension_) == 1);
        }
        
        // Populate supports based on is_cs_ flag
        if (is_cs_) {
            for (uint64_t support = 1ULL; support < bs64::two_to_the_power_of(dimension_); ++support) {
                size_t current_index = bs64::count_set_bits(support) - 1;
                if (is_coprime[current_index]) {
                    // Only add if it's the smallest representation (canonical form)
                    if (bs64::is_smallest_representation(support, dimension_)) {
                        supports_[current_index].push_back(support);
                    }
                } else {
                    supports_[current_index].push_back(support);
                }
            }
        } else {
            for (uint64_t bits = 1ULL; bits < bs64::two_to_the_power_of(dimension_); ++bits) {
                bitset64 support = bits;
                supports_[bs64::count_set_bits(support) - 1].push_back(support);
            }
        }
    }
    
    /// Get const reference to supports for a given support size (1-indexed)
    /// CRITICAL hot path - must be FORCE_INLINE
    inline const std::vector<bitset64>& get_supports(size_t support_size) const noexcept {
        return supports_[support_size-1];
    }
    
    /// Remove all supersets of the given subset, starting from from_size
    /// Hot path - FORCE_INLINE for maximum performance
    inline void remove_supersets(const bitset64& subset, uint64_t support_size = 0) noexcept {
        if (support_size == 0) {
            support_size = bs64::count_set_bits(subset);
        }
        for (size_t i = support_size; i < dimension_; ++i) { //index support_size means erase from support_size+1 on!!!
            auto& vec = supports_[i];
            // Binary search: find first element where x > subset (only for dimension >= 10)
            // this is an educated guess. for small dimensions the overhead of the binary search is bigger than the time saved
            auto start_it = (dimension_ >= 10) 
                ? std::upper_bound(vec.begin(), vec.end(), subset)
                : vec.begin();
            // Only check elements from start_it onwards
            if (start_it != vec.end()) {
                vec.erase(
                std::remove_if(
                        start_it,
                        vec.end(),
                    [=](const bitset64& x) { return bs64::is_subset_of(subset, x); }
                ),
                    vec.end()
            );
            }
        }
    }
    
};


=== cpp/include/rational_linalg/adjugate.hpp ===
#ifndef RATIONAL_LINALG_ADJUGATE_HPP
#define RATIONAL_LINALG_ADJUGATE_HPP

#include <rational_linalg/matrix.hpp>
#include <rational_linalg/lu.hpp>

namespace rational_linalg {

// Compute adjugate using cofactor expansion with LUFactor
template<typename T>
inline Matrix<T> adjugate(const Matrix<T>& A) {
    const size_t n = A.rows();
    
    // Handle edge cases
    if (n == 0) {
        return Matrix<T>(0, 0);
    }
    
    if (n == 1) {
        Matrix<T> result(1, 1);
        result(0, 0) = T(1);
        return result;
    }
    
    // Build cofactor matrix
    Matrix<T> cofactor_matrix(n, n);
    
    // Reuse a single minor matrix to avoid n² allocations
    Matrix<T> minor(n - 1, n - 1);
    
    for (size_t i = 0; i < n; ++i) {
        for (size_t j = 0; j < n; ++j) {
            // Extract minor M_ij (remove row i, column j) into reused matrix
            size_t minor_row = 0;
            for (size_t row = 0; row < n; ++row) {
                if (row == i) continue;
                size_t minor_col = 0;
                for (size_t col = 0; col < n; ++col) {
                    if (col == j) continue;
                    minor(minor_row, minor_col) = A(row, col);
                    ++minor_col;
                }
                ++minor_row;
            }
            
            // Compute determinant of minor using LUFactor
            LUFactor<T> lu(minor);
            T det_minor = lu.determinant();
            
            // Compute cofactor: (-1)^(i+j) * det(M_ij)
            // Use bitwise AND for sign: (i+j) & 1 is faster than % 2
            T sign = ((i + j) & 1) == 0 ? T(1) : T(-1);
            cofactor_matrix(i, j) = sign * det_minor;
        }
    }
    
    // Adjugate is the transpose of the cofactor matrix
    return cofactor_matrix.transpose();
}

} // namespace rational_linalg

#endif // RATIONAL_LINALG_ADJUGATE_HPP


=== cpp/include/rational_linalg/bareiss_lu.hpp ===
#ifndef RATIONAL_LINALG_BAREISS_LU_HPP
#define RATIONAL_LINALG_BAREISS_LU_HPP

#include <rational_linalg/matrix.hpp>
#include <stdexcept>

namespace rational_linalg {

/*
 * BareissLUFactor (fraction-free LU factorization) for Matrix<T>
 *
 * Speed:
 *   - Complexity: O(n^3), same as standard LU.
 *   - Much slower in practice with rational or big integer types
 *     because intermediate numbers grow rapidly.
 *   - For floating-point, Bareiss is slower than PartialPivLU
 *     because it avoids floating-point division tricks and uses exact arithmetic.
 *
 * Stability / Accuracy:
 *   - Perfect for fractional or symbolic types; no rounding errors.
 *   - Detects singular matrices exactly (pivot = 0).
 *   - Great for ill-conditioned matrices in exact arithmetic because
 *     no division by small numbers until necessary.
 *   - Cannot suffer from numerical instability in exact arithmetic.
 *
 * Use case:
 *   - Exact solutions, guaranteed singularity detection,
 *     symbolic or fractional arithmetic.
 */

template<typename T>
class BareissLUFactor {
public:
    using Scalar = T;
    using VectorType = Matrix<T>;

    BareissLUFactor(const Matrix<T>& A) {
        compute(A);
    }

    // ------------------------------------------------------------------------
    // Perform fraction-free LU factorization using Bareiss algorithm
    // ------------------------------------------------------------------------
    void compute(const Matrix<T>& A) {
        const size_t n = A.rows();
        m_n = n;
        m_L = Matrix<T>::identity(n);
        m_U = A;
        m_P = Matrix<T>::identity(n);
        m_swap_count = 0;

        T divPrev = T(1);

        for (size_t k = 0; k < n - 1; ++k) {

            // ----- Partial Pivoting -----
            size_t max_row = k;
            T max_val = m_U(k, k);
            if (max_val < T(0)) max_val = -max_val;
            
            for (size_t i = k + 1; i < n; ++i) {
                T val = m_U(i, k);
                if (val < T(0)) val = -val;
                if (val > max_val) {
                    max_val = val;
                    max_row = i;
                }
            }
            
            if (max_row != k) {
                m_U.swap_rows(k, max_row);
                m_P.swap_rows(k, max_row);
                // L rows up to k-1 also swap to maintain LU decomposition
                if (k > 0) {
                    for (size_t j = 0; j < k; ++j) {
                        T tmp = m_L(k, j);
                        m_L(k, j) = m_L(max_row, j);
                        m_L(max_row, j) = tmp;
                    }
                }
                m_swap_count++;
            }
            
            const T pivot = m_U(k, k);
            if (pivot == T(0)) {
                m_is_singular = true;
                return;
            }

            // ----- Bareiss Fraction-Free Update -----
            for (size_t i = k + 1; i < n; ++i) {
                m_L(i, k) = m_U(i, k) / pivot;   // store multiplier

                for (size_t j = k + 1; j < n; ++j) {
                    m_U(i, j) =
                        (m_U(i, j) * pivot - m_U(i, k) * m_U(k, j)) / divPrev;
                }
                m_U(i, k) = T(0);
            }

            divPrev = pivot;
        }

        m_is_singular = (m_U(n - 1, n - 1) == T(0));
    }

    // ------------------------------------------------------------------------
    // Compute exact determinant
    // ------------------------------------------------------------------------
    T determinant() const {
        if (m_is_singular) return T(0);

        T det = T(1);

        // determinant(P) = sign of permutation = (-1)^(swap_count)
        if (m_swap_count % 2 == 1) det = T(-1);

        for (size_t i = 0; i < m_n; ++i)
            det *= m_U(i, i);

        return det;
    }

    // ------------------------------------------------------------------------
    // Compute inverse matrix via LU solve
    // ------------------------------------------------------------------------
    Matrix<T> inverse() const {
        Matrix<T> Inv(m_n, m_n);

        if (m_is_singular)
            throw std::runtime_error("Matrix is singular");

        for (size_t col = 0; col < m_n; ++col) {
            Matrix<T> e = Matrix<T>::Zero(m_n);
            e(col, 0) = T(1);
            Matrix<T> col_result = solve(e);
            // Copy column result into inverse
            for (size_t i = 0; i < m_n; ++i) {
                Inv(i, col) = col_result(i, 0);
            }
        }

        return Inv;
    }

    // ------------------------------------------------------------------------
    // Solve Ax = b using computed LU: A = P^T * L * U
    // ------------------------------------------------------------------------
    Matrix<T> solve(const Matrix<T>& b) const {
        // b must be a column vector
        if (b.cols() != 1 || b.rows() != m_n) {
            throw std::runtime_error("solve: b must be a column vector of size n");
        }
        
        // Apply permutation: bp = P * b
        Matrix<T> bp(m_n, 1);
        for (size_t i = 0; i < m_n; ++i) {
            T sum = T(0);
            for (size_t j = 0; j < m_n; ++j) {
                sum += m_P(i, j) * b(j, 0);
            }
            bp(i, 0) = sum;
        }
        
        Matrix<T> y(m_n, 1);
        Matrix<T> x(m_n, 1);

        // Forward substitution: L y = bp
        for (size_t i = 0; i < m_n; ++i) {
            T sum = bp(i, 0);
            for (size_t j = 0; j < i; ++j)
                sum -= m_L(i, j) * y(j, 0);
            y(i, 0) = sum;
        }

        // Back substitution: U x = y
        for (size_t i = m_n; i-- > 0; ) {
            T sum = y(i, 0);
            for (size_t j = i + 1; j < m_n; ++j)
                sum -= m_U(i, j) * x(j, 0);
            x(i, 0) = sum / m_U(i, i);
        }

        return x;
    }

    bool isSingular() const { return m_is_singular; }

private:
    size_t m_n;
    Matrix<T> m_L, m_U, m_P;
    bool m_is_singular = false;
    int m_swap_count = 0;
};

} // namespace rational_linalg

#endif // RATIONAL_LINALG_BAREISS_LU_HPP


=== cpp/include/rational_linalg/copositivity.hpp ===
#ifndef RATIONAL_LINALG_COPOSITIVITY_HPP
#define RATIONAL_LINALG_COPOSITIVITY_HPP

#include <cstddef>
#include <rational_linalg/matrix.hpp>
#include <rational_linalg/bareiss_lu.hpp>
#include <rational_linalg/adjugate.hpp>
#include <fracessa/bitset64.hpp>
#include <unordered_map>

// Hash function for bitset64 to use with std::unordered_map
struct bitset64_hash {
    std::size_t operator()(const bitset64& bs) const noexcept {
        return bs64::hash(bs);
    }
};

namespace rational_linalg {

// Memoization cache: maps bitset64 mask to bool result
template<typename T>
class CopositivityChecker {
private:
    std::unordered_map<bitset64, bool, bitset64_hash> memo;

    // Recursive Check (Hadeler Criterion) for Fractions
    bool checkRecursive(const Matrix<T>& A, const bitset64& mask) {
        // 1. Check Cache
        auto it = memo.find(mask);
        if (it != memo.end()) {
            return it->second;
        }

        size_t current_dim = bs64::count_set_bits(mask);

        // 2. Base Case: 1x1 Matrix
        if (current_dim == 1) {
            unsigned idx = bs64::find_pos_first_set_bit(mask);
            // Check if diagonal element > 0 (Rational comparison)
            bool result = A(static_cast<size_t>(idx), static_cast<size_t>(idx)) > T(0);
            memo[mask] = result;
            return result;
        }

        // 3. Recursive Step: Check all submatrices of size (current_dim - 1)
        // We iterate ONLY over the bits that are currently set to turn them off one by one
        bool all_good = true;
        for (size_t i = bs64::find_pos_first_set_bit(mask); i < 64; i = bs64::find_pos_next_set_bit(mask, i)) {
            bitset64 sub_mask = bs64::clear_bit_at_pos(mask, i); // Turn off bit i representing row/col i
            if (!checkRecursive(A, sub_mask)) {
                all_good = false;
                break; // Fail early
            }
        }
        if (!all_good) {
            memo[mask] = false; // Fail early
            return false;
        }

        // 4. Determinant / Adjugate Check
        // If all proper principal submatrices are strictly copositive,
        // A is strictly copositive UNLESS (det(A) <= 0 AND adj(A) > 0)
        
        // Use principal_submatrix which already uses optimized find_first()/find_next() iteration
        Matrix<T> subMat = A.principal_submatrix(mask);

        // Use BareissLUFactor for determinant and inverse
        BareissLUFactor<T> lu(subMat);
        T det = lu.determinant();

        if (det <= T(0)) {
            // Compute Adjugate: adj(A) = det(A) * A^(-1)
            // For singular matrices (det = 0), we can't use the inverse formula
            // because A^(-1) doesn't exist. We need to compute adjugate differently.
            Matrix<T> adj;
            if (lu.isSingular()) {
                // Fall back to cofactor method for singular matrices
                adj = adjugate(subMat);
            } else {
                // For det < 0, we can use the inverse formula, is cheaper!!!
                adj = lu.inverse() * det;
            }

            // Check if Adjugate is Strictly Positive (> 0)
            if (adj.all_entries_greater_zero()) {
                memo[mask] = false; // Violates Hadeler condition
                return false;
            }
        }

        // Passed all checks
        memo[mask] = true;
        return true;
    }

public:
    // Main Entry Point
    bool isStrictlyCopositiveMemoized(const Matrix<T>& A) {
        size_t n = A.rows();
        // Clear cache for new computation
        memo.clear();       
        // Reserve map size to avoid reallocations (heuristic: worst case 2^n subsets)
        memo.reserve(bs64::two_to_the_power_of(n));
        
        bitset64 full_mask = bs64::set_all_n_bits(n);
        return checkRecursive(A, full_mask);
    }
};

// Convenience function
template<typename T>
inline bool isStrictlyCopositiveMemoized(const Matrix<T>& A) {
    CopositivityChecker<T> checker;
    return checker.isStrictlyCopositiveMemoized(A);
}

} // namespace rational_linalg

#endif // RATIONAL_LINALG_COPOSITIVITY_HPP


=== cpp/include/rational_linalg/fraction.hpp ===
#pragma once

#include <flint/flint.h>  // For slong and basic types
#include <flint/fmpq.h>
#include <stdexcept>
#include <string>
#include <ostream>
#include <cstdlib>  // For free()

namespace rational_linalg {

// ============================================================================
// fraction - OPTIMIZED FLINT Rational Number Wrapper
// ============================================================================
// Thin C++17 wrapper around FLINT's fmpq_t for arbitrary-precision rationals
// ============================================================================

class fraction {
private:
    fmpq_t data_;
    
public:
    // ========================================================================
    // Constructors
    // ========================================================================
    
    // Default constructor (zero)
    fraction() noexcept {
        fmpq_init(data_);
    }
    
    // From long
    explicit fraction(long num, long den = 1) noexcept {
        fmpq_init(data_);
        fmpq_set_si(data_, num, den);
        fmpq_canonicalise(data_);
    }
    
    // From long long
    explicit fraction(long long num, long long den = 1) noexcept {
        fmpq_init(data_);
        fmpq_set_si(data_, static_cast<slong>(num), static_cast<slong>(den));
        fmpq_canonicalise(data_);
    }
    
    // From int (non-explicit for compatibility with T(0), T(1) patterns)
    fraction(int num, int den = 1) noexcept {
        fmpq_init(data_);
        fmpq_set_si(data_, static_cast<slong>(num), static_cast<slong>(den));
        fmpq_canonicalise(data_);
    }
    
    // Copy constructor
    fraction(const fraction& other) noexcept {
        fmpq_init(data_);
        fmpq_set(data_, other.data_);
    }
    
    // FIXED: Correct move constructor using swap
    fraction(fraction&& other) noexcept {
        fmpq_init(data_);
        fmpq_swap(data_, other.data_);
    }
    
    // Destructor
    ~fraction() noexcept {
        fmpq_clear(data_);
    }
    
    // ========================================================================
    // Assignment Operators
    // ========================================================================
    
    // Copy assignment
    fraction& operator=(const fraction& other) noexcept {
        if (this != &other) {
            fmpq_set(data_, other.data_);
        }
        return *this;
    }
    
    // FIXED: Correct move assignment using swap
    fraction& operator=(fraction&& other) noexcept {
        if (this != &other) {
            fmpq_swap(data_, other.data_);
        }
        return *this;
    }
    
    // ========================================================================
    // Direct Access to Underlying FLINT Type (Zero Overhead)
    // ========================================================================
    
    fmpq_t& data() noexcept { return data_; }
    const fmpq_t& data() const noexcept { return data_; }
    
    // Get pointer for direct FLINT operations
    fmpq* ptr() noexcept { return data_; }
    const fmpq* ptr() const noexcept { return data_; }
    
    // ========================================================================
    // In-Place Operations (FAST - No Temporaries)
    // ========================================================================
    
    void add_inplace(const fraction& other) noexcept {
        fmpq_add(data_, data_, other.data_);
    }
    
    void sub_inplace(const fraction& other) noexcept {
        fmpq_sub(data_, data_, other.data_);
    }
    
    void mul_inplace(const fraction& other) noexcept {
        fmpq_mul(data_, data_, other.data_);
    }
    
    void div_inplace(const fraction& other) {
        if (fmpq_is_zero(other.data_)) {
            throw std::domain_error("Division by zero");
        }
        fmpq_div(data_, data_, other.data_);
    }
    
    void negate_inplace() noexcept {
        fmpq_neg(data_, data_);
    }
    
    void abs_inplace() noexcept {
        fmpq_abs(data_, data_);
    }
    
    // ========================================================================
    // Arithmetic Operators (RVO-Friendly)
    // ========================================================================
    
    fraction operator+(const fraction& other) const {
        fraction result;
        fmpq_add(result.data_, data_, other.data_);
        return result;
    }
    
    fraction operator-(const fraction& other) const {
        fraction result;
        fmpq_sub(result.data_, data_, other.data_);
        return result;
    }
    
    fraction operator*(const fraction& other) const {
        fraction result;
        fmpq_mul(result.data_, data_, other.data_);
        return result;
    }
    
    fraction operator/(const fraction& other) const {
        if (fmpq_is_zero(other.data_)) {
            throw std::domain_error("Division by zero");
        }
        fraction result;
        fmpq_div(result.data_, data_, other.data_);
        return result;
    }
    
    fraction operator-() const {
        fraction result;
        fmpq_neg(result.data_, data_);
        return result;
    }
    
    // ========================================================================
    // Compound Assignment Operators (Use In-Place Operations)
    // ========================================================================
    
    fraction& operator+=(const fraction& other) noexcept {
        add_inplace(other);
        return *this;
    }
    
    fraction& operator-=(const fraction& other) noexcept {
        sub_inplace(other);
        return *this;
    }
    
    fraction& operator*=(const fraction& other) noexcept {
        mul_inplace(other);
        return *this;
    }
    
    fraction& operator/=(const fraction& other) {
        div_inplace(other);
        return *this;
    }
    
    // ========================================================================
    // Comparison Operators (noexcept)
    // ========================================================================
    
    bool operator==(const fraction& other) const noexcept {
        return fmpq_equal(data_, other.data_);
    }
    
    bool operator!=(const fraction& other) const noexcept {
        return !fmpq_equal(data_, other.data_);
    }
    
    bool operator<(const fraction& other) const noexcept {
        return fmpq_cmp(data_, other.data_) < 0;
    }
    
    bool operator<=(const fraction& other) const noexcept {
        return fmpq_cmp(data_, other.data_) <= 0;
    }
    
    bool operator>(const fraction& other) const noexcept {
        return fmpq_cmp(data_, other.data_) > 0;
    }
    
    bool operator>=(const fraction& other) const noexcept {
        return fmpq_cmp(data_, other.data_) >= 0;
    }
    
    // ========================================================================
    // Utility Functions
    // ========================================================================
    
    bool is_zero() const noexcept {
        return fmpq_is_zero(data_);
    }
    
    bool is_one() const noexcept {
        return fmpq_is_one(data_);
    }
    
    fraction abs() const noexcept {
        fraction result;
        fmpq_abs(result.data_, data_);
        return result;
    }
    
    fraction inverse() const {
        if (fmpq_is_zero(data_)) {
            throw std::domain_error("Cannot invert zero");
        }
        fraction result;
        fmpq_inv(result.data_, data_);
        return result;
    }
    
    // ========================================================================
    // Conversions
    // ========================================================================
    
    // Convert to double (ONLY conversion implemented)
    double to_double() const noexcept {
        return fmpq_get_d(data_);
    }
    
    // String representation
    std::string to_string() const {
        char* str = fmpq_get_str(nullptr, 10, data_);
        if (str == nullptr) {
            return "0";
        }
        std::string result(str);
        free(str);  // FLINT's fmpq_get_str uses malloc, so use free()
        return result;
    }
    
    // Stream output - optimized to write directly without string allocation
    friend std::ostream& operator<<(std::ostream& os, const fraction& r) {
        char* str = fmpq_get_str(nullptr, 10, r.data_);
        if (str == nullptr) {
            os << "0";
        } else {
            os << str;  // Write directly to stream, no string allocation
            free(str);
        }
        return os;
    }
};

// ============================================================================
// Helper Functions
// ============================================================================

} // namespace rational_linalg

// Global type alias for convenience
typedef rational_linalg::fraction fraction;

=== cpp/include/rational_linalg/linear_solver.hpp ===
#ifndef RATIONAL_LINALG_LINEAR_SOLVER_HPP
#define RATIONAL_LINALG_LINEAR_SOLVER_HPP

#include <rational_linalg/matrix.hpp>
#include <cmath>
#include <limits>

namespace rational_linalg {

/*
 * BareissGauss (fraction-free Gaussian elimination) solver for Matrix<T>
 *
 * Speed:
 *   - Complexity: O(n^3), same as standard Gaussian elimination.
 *   - Much slower in practice with fractional or big integer types
 *     because intermediate numbers grow rapidly.
 *   - For floating-point, Bareiss is slower than standard methods
 *     because it avoids floating-point division tricks and uses exact arithmetic.
 *
 * Stability / Accuracy:
 *   - Perfect for fractional or symbolic types; no rounding errors.
 *   - Detects singular matrices exactly (pivot = 0).
 *   - Great for ill-conditioned matrices in exact arithmetic because
 *     no division by small numbers until necessary.
 *   - Cannot suffer from numerical instability in exact arithmetic.
 *
 * Use case:
 *   - Exact solutions, guaranteed singularity detection,
 *     symbolic or fractional arithmetic.
 */

template<typename T>
class BareissGauss {
public:
    using Scalar = T;
    using VectorType = Matrix<T>;

    explicit BareissGauss(const Matrix<T>& Ab) : M(Ab) {}

    bool solve(Matrix<T>& x) {
        const size_t n = M.rows();

        T divPrev = T(1);

        // Bareiss elimination with partial pivoting
        for (size_t k = 0; k < n - 1; ++k) {
            // Partial pivoting: find row with maximum absolute value in column k
            size_t max_row = k;
            T max_val = M(k, k);
            if (max_val < T(0)) max_val = -max_val;
            
            for (size_t i = k + 1; i < n; ++i) {
                T val = M(i, k);
                if (val < T(0)) val = -val;
                if (val > max_val) {
                    max_val = val;
                    max_row = i;
                }
            }
            
            // Swap rows if necessary
            if (max_row != k) {
                M.swap_rows(k, max_row);
            }
            
            const T pivot = M(k, k);
            if (pivot == T(0)) {
                return false;
            }

            // Bareiss elimination step
            for (size_t i = k + 1; i < n; ++i) {
                for (size_t j = k + 1; j <= n; ++j) {
                    M(i, j) = (M(i, j) * pivot - M(i, k) * M(k, j)) / divPrev;
                }
                M(i, k) = T(0); // Zero out eliminated element (not updated in inner loop)
            }

            divPrev = pivot;
        }

        if (M(n - 1, n - 1) == T(0)) return false;

        // Back substitution
        x = Matrix<T>(n, 1);
        for (size_t i = n; i-- > 0; ) {
            T sum = M(i, n);
            for (size_t j = i + 1; j < n; ++j) {
                sum -= M(i, j) * x(j, 0);
            }

            const T pivot = M(i, i);

            if (pivot == T(0)) 
                return false;            

            T temp_x = sum / pivot;
            if (temp_x <= T(0))
                return false; //early exit if sum is not >zero! then it cannot be a solution (since x on the simplex is always positive!)
            else
                x(i, 0) = temp_x;
        }

        return true;
    }

private:
    Matrix<T> M;
};

/*
 * GaussDouble - Optimized standard Gaussian elimination for Matrix<double>
 *
 * Speed:
 *   - Complexity: O(n^3), same as BareissGauss
 *   - Much faster than BareissGauss for double because:
 *     - Uses direct division (no fraction-free arithmetic overhead)
 *     - Optimized for floating-point operations
 *     - Better cache locality
 *
 * Stability / Accuracy:
 *   - Uses partial pivoting for numerical stability
 *   - Tolerance-based singularity detection
 *   - Standard floating-point precision limitations apply
 *
 * Use case:
 *   - Fast solving of double-precision linear systems
 *   - When exact arithmetic is not required
 */


// class GaussDouble {
// public:
//     using Scalar = double;
//     using VectorType = Matrix<double>;

//     explicit GaussDouble(const Matrix<double>& Ab) : M(Ab) {}

//     bool solve(Matrix<double>& x) {
//         const size_t n = M.rows();

//         const double errorbound = 1e-5 * n; // huge margin, false positives eliminated by fractional check

//         const double epsilon = 1e-15; //std::numeric_limits<double>::epsilon(); // * n; keep epsilon super small to avoid false negative. false positive will be detected by fractional afterwards!!!

//         // Standard Gaussian elimination with partial pivoting
//         for (size_t k = 0; k < n - 1; ++k) {
//             // Partial pivoting: find row with maximum absolute value in column k
//             size_t max_row = k;
//             double max_val = std::abs(M(k, k));
            
//             for (size_t i = k + 1; i < n; ++i) {
//                 double val = std::abs(M(i, k));
//                 if (val > max_val) {
//                     max_val = val;
//                     max_row = i;
//                 }
//             }
            
//             // Check for singularity
//             if (max_val < epsilon) {
//                 return false;
//             }
            
//             // Swap rows if necessary
//             if (max_row != k) {
//                 M.swap_rows(k, max_row);
//             }
            
//             const double pivot = M(k, k);

//             // Standard elimination step (direct division, no fraction-free)
//             for (size_t i = k + 1; i < n; ++i) {
//                 const double factor = M(i, k) / pivot;
//                 for (size_t j = k + 1; j <= n; ++j) {
//                     M(i, j) -= factor * M(k, j);
//                 }
//                 M(i, k) = 0.0; // Zero out eliminated element (not updated in inner loop)
//             }
//         }

//         // Check last pivot
//         if (std::abs(M(n - 1, n - 1)) < epsilon) {
//             return false;
//         }

//         // Back substitution
//         x = Matrix<double>(n, 1);
//         for (size_t i = n; i-- > 0; ) {
//             double sum = M(i, n);
//             for (size_t j = i + 1; j < n; ++j) {
//                 sum -= M(i, j) * x(j, 0);
//             }

//             const double pivot = M(i, i);
//             if (std::abs(pivot) < epsilon) {
//                 return false;
//             }

//             double temp_x = sum / pivot;
//             // Check for not >zero in solution component with huge margin
//             // False positives will be eliminated by fractional checks later
//             if (temp_x < -errorbound) 
//                 return false;
//             else
//                 x(i, 0) = temp_x;
//         }

//         return true;
//     }

// private:
//     Matrix<double> M;
// };

/*
 * GaussDouble - STRICTLY OPTIMIZED
 * 
 * 1. NO HEAP ALLOCATIONS (Fixes the slowdown).
 * 2. Pointer Hoisting: Calculates row addresses once per row.
 * 3. Physical Swapping: Faster than virtual pivoting for small N (fits in L1 cache).
 */
 class GaussDouble {
    public:
        using Scalar = double;
        using VectorType = Matrix<double>;
    
        explicit GaussDouble(Matrix<double>& Ab) : M(Ab) {}
    
        bool solve(Matrix<double>& x) {
            const size_t n = M.rows();
            const size_t cols = M.cols(); // n+1 usually
            double* data = M.data();
    
            const double errorbound = 1e-5 * n; 
            const double epsilon = 1e-15; 
    
            // Forward elimination
            for (size_t k = 0; k < n - 1; ++k) {
                
                // 1. Partial Pivoting
                size_t max_row = k;
                double max_val = std::abs(data[k * cols + k]);
                
                for (size_t i = k + 1; i < n; ++i) {
                    double val = std::abs(data[i * cols + k]);
                    if (val > max_val) {
                        max_val = val;
                        max_row = i;
                    }
                }
                
                if (max_val < epsilon) return false;
                
                // Physical Swap (Fast for small N)
                if (max_row != k) {
                    // Swap rows manually using pointers to avoid index math overhead
                    double* row_k = data + k * cols;
                    double* row_max = data + max_row * cols;
                    // Swap the relevant part of the row (k to end is enough, but cols is safe)
                    // We swap the whole row to be safe with the layout
                    for(size_t j=0; j < cols; ++j) {
                         std::swap(row_k[j], row_max[j]);
                    }
                }
                
                // Hoist pivot pointer
                double* pivot_row = data + k * cols;
                const double pivot = pivot_row[k];
    
                // 2. Elimination
                for (size_t i = k + 1; i < n; ++i) {
                    double* curr_row = data + i * cols;
                    
                    const double factor = curr_row[k] / pivot;
                    curr_row[k] = 0.0; 
                    
                    // Vectorizable inner loop
                    for (size_t j = k + 1; j <= n; ++j) { // <= n includes the b vector
                        curr_row[j] -= factor * pivot_row[j];
                    }
                }
            }
    
            // Check last pivot
            if (std::abs(data[(n - 1) * cols + (n - 1)]) < epsilon) {
                return false;
            }
    
            // 3. Back substitution
            x = Matrix<double>(n, 1);
            for (size_t i = n; i-- > 0; ) {
                const double* row_ptr = data + i * cols;
                double sum = row_ptr[n]; // b vector
                
                for (size_t j = i + 1; j < n; ++j) {
                    sum -= row_ptr[j] * x(j, 0);
                }
    
                const double pivot = row_ptr[i];
                if (std::abs(pivot) < epsilon) return false;
    
                double temp_x = sum / pivot;
                if (temp_x < -errorbound) return false;
                
                x(i, 0) = temp_x;
            }
    
            return true;
        }
    
    private:
        Matrix<double>& M;
    };


    
/*
 * GaussRational<T> - Generic standard Gaussian elimination for Matrix<T>
 *
 * Speed:
 *   - Complexity: O(n^3), same as BareissGauss
 *   - Faster than BareissGauss for types that support efficient division:
 *     - Uses direct division (no fraction-free arithmetic overhead)
 *     - Better for fractional types when intermediate values don't grow too large
 *     - More efficient for floating-point types
 *
 * Stability / Accuracy:
 *   - Uses partial pivoting for numerical stability
 *   - Exact zero detection for singularity (no tolerance needed for exact types)
 *   - For floating-point types, may suffer from numerical instability
 *     compared to BareissGauss for ill-conditioned matrices
 *
 * Use case:
 *   - Fast solving of linear systems when exact arithmetic is available
 *   - Alternative to BareissGauss when division is efficient
 *   - For fractional types when matrix is well-conditioned
 */
// template<typename T>
// class GaussRational {
// public:
//     using Scalar = T;
//     using VectorType = Matrix<T>;

//     explicit GaussRational(const Matrix<T>& Ab) : M(Ab) {}

//     bool solve(Matrix<T>& x) {
//         const size_t n = M.rows();

//         // Standard Gaussian elimination with partial pivoting
//         for (size_t k = 0; k < n - 1; ++k) {
//             // Partial pivoting: find row with maximum absolute value in column k
//             size_t max_row = k;
//             T max_val = M(k, k);
//             if (max_val < T(0)) max_val = -max_val;
            
//             for (size_t i = k + 1; i < n; ++i) {
//                 T val = M(i, k);
//                 if (val < T(0)) val = -val;
//                 if (val > max_val) {
//                     max_val = val;
//                     max_row = i;
//                 }
//             }
            
//             // Check for singularity (exact zero check for generic types)
//             if (max_val == T(0)) {
//                 return false;
//             }
            
//             // Swap rows if necessary
//             if (max_row != k) {
//                 M.swap_rows(k, max_row);
//             }
            
//             const T pivot = M(k, k);

//             // Standard elimination step (direct division, no fraction-free)
//             for (size_t i = k + 1; i < n; ++i) {
//                 const T factor = M(i, k) / pivot;
//                 for (size_t j = k + 1; j <= n; ++j) {
//                     M(i, j) -= factor * M(k, j);
//                 }
//                 M(i, k) = T(0); // Zero out eliminated element (not updated in inner loop)
//             }
//         }

//         // Check last pivot
//         if (M(n - 1, n - 1) == T(0)) {
//             return false;
//         }

//         // Back substitution
//         x = Matrix<T>(n, 1);
//         for (size_t i = n; i-- > 0; ) {
//             T sum = M(i, n);
//             for (size_t j = i + 1; j < n; ++j) {
//                 sum -= M(i, j) * x(j, 0);
//             }

//             const T pivot = M(i, i);

//             if (pivot == T(0)) 
//                 return false;

//             T temp_x = sum / pivot;
//             if (temp_x <= T(0))
//                 return false; //early exit if sum is not >zero! 
//                 //then it cannot be a solution: full support for this subgame <=> x is in the interior of the (sub)simplex <=> all x_i are positive!
//             else
//                 x(i, 0) = temp_x;               
//         }

//         return true;
//     }

// private:
//     Matrix<T> M;
// };

/*
 * GaussRational<T> - Optimized Standard Gaussian elimination.
 * 
 * OPTIMIZATIONS:
 * 1. Uses fmpq_submul (FLINT) for direct subtraction-multiplication without temporaries.
 * 2. Uses Virtual Pivoting to avoid expensive row swaps in memory.
 */
 template<typename T>
 class GaussRational {
 public:
     using Scalar = T;
     using VectorType = Matrix<T>;
 
     // Constructor accepts non-const ref to modify directly (copy is made by caller/MatrixServer usually, or we assume local scratchpad)
     explicit GaussRational(Matrix<T>& Ab) : M(Ab) {}
 
     bool solve(Matrix<T>& x) {
         const size_t n = M.rows();
 
         // Virtual pivoting map: p[i] stores the physical row index for logical row i
         std::vector<size_t> p(n);
         for (size_t i = 0; i < n; ++i) p[i] = i;
 
         // Forward elimination
         for (size_t k = 0; k < n - 1; ++k) {
             // Partial pivoting
             size_t max_row_logical = k;
             
             // For exact types, finding ANY non-zero is sufficient for solvability, 
             // though max abs value keeps coefficient growth slightly cleaner.
             // Using a simple non-zero check is fastest if we trust FLINT's GCD.
             // Let's stick to simple "first non-zero" or "current if non-zero" to avoid abs() overhead, 
             // or implement full abs comparison if needed. 
             // Here, we check if current pivot is zero. If so, search for a non-zero.
             
             fmpq* max_val_ptr = M(p[k], k).ptr();
             
             if (fmpq_is_zero(max_val_ptr)) {
                 bool found = false;
                 for (size_t i = k + 1; i < n; ++i) {
                     fmpq* val_ptr = M(p[i], k).ptr();
                     if (!fmpq_is_zero(val_ptr)) {
                         max_row_logical = i;
                         max_val_ptr = val_ptr;
                         found = true;
                         break;
                     }
                 }
                 if (!found) return false; // Singular column
             }
             
             // Swap virtual rows
             if (max_row_logical != k) {
                 std::swap(p[k], p[max_row_logical]);
             }
             
             const size_t pivot_row_idx = p[k];
             fmpq* pivot_ptr = M(pivot_row_idx, k).ptr(); // Corrected type: fmpq*
 
             // Elimination
             for (size_t i = k + 1; i < n; ++i) {
                 size_t curr_row_idx = p[i];
                 fmpq* target_ptr = M(curr_row_idx, k).ptr(); // Corrected type: fmpq*
 
                 if (fmpq_is_zero(target_ptr)) continue;
 
                 // factor = M(i, k) / pivot
                 // We use a temporary fmpq_t. It acts as fmpq* when passed to functions.
                 fmpq_t factor;
                 fmpq_init(factor);
                 fmpq_div(factor, target_ptr, pivot_ptr);
 
                 // Row_i -= factor * Row_k
                 // Optimize: Start from k+1 (cols 0..k become 0)
                 for (size_t j = k + 1; j <= n; ++j) {
                     // M(i, j) = M(i, j) - factor * M(k, j)
                     // fmpq_submul(rop, op1, op2) -> rop = rop - op1 * op2
                     fmpq_submul(M(curr_row_idx, j).ptr(), factor, M(pivot_row_idx, j).ptr());
                 }
                 
                 // Explicitly zero out the eliminated element
                 fmpq_zero(target_ptr);
                 fmpq_clear(factor);
             }
         }
 
         // Check last pivot
         if (M(p[n - 1], n - 1).is_zero()) {
             return false;
         }
 
         // Back substitution
         x = Matrix<T>(n, 1);
         for (size_t i = n; i-- > 0; ) {
             size_t row_idx = p[i];
             
             // sum = b[i] (which is in column n)
             // Use temp to accumulate to safely use fmpq_submul
             fmpq_t sum;
             fmpq_init(sum);
             fmpq_set(sum, M(row_idx, n).ptr());
 
             for (size_t j = i + 1; j < n; ++j) {
                 fmpq_submul(sum, M(row_idx, j).ptr(), x(j, 0).ptr());
             }
 
             // x[i] = sum / M[i, i]
             fmpq* pivot_ptr = M(row_idx, i).ptr();
             
             // Division
             fmpq_div(x(i, 0).ptr(), sum, pivot_ptr);
             
             // Early exit: x must be > 0
             // fmpq_sgn returns positive (>0), zero (0), negative (<0)
             if (fmpq_sgn(x(i, 0).ptr()) <= 0) {
                 fmpq_clear(sum);
                 return false; 
             }
 
             fmpq_clear(sum);
         }
 
         return true;
     }
 
 private:
     Matrix<T>& M;
 };


// Helper struct for automatic solver selection
// Automatically selects GaussDouble for double, GaussRational<T> for other types
template<typename T>
struct SolverSelector {
    using type = GaussRational<T>;
    //using type = BareissGauss<T>; //leave this here!!! for comparison!!!
};

template<>
struct SolverSelector<double> {
    using type = GaussDouble;
};

// Type alias for automatic solver selection
template<typename T>
using LinearSolver = typename SolverSelector<T>::type;

} // namespace rational_linalg

#endif // RATIONAL_LINALG_LINEAR_SOLVER_HPP


=== cpp/include/rational_linalg/lu.hpp ===
#ifndef RATIONAL_LINALG_LU_HPP
#define RATIONAL_LINALG_LU_HPP

#include <rational_linalg/matrix.hpp>
#include <stdexcept>

namespace rational_linalg {

/*
 * LUFactor (standard LU factorization with partial pivoting) for Matrix<T>
 *
 * Speed:
 *   - Complexity: O(n^3), same as Bareiss LU.
 *   - Faster in practice with rational or big integer types
 *     because intermediate numbers don't grow as rapidly as Bareiss.
 *   - Standard division at each step, but simpler computation.
 *
 * Stability / Accuracy:
 *   - Perfect for fractional or symbolic types; no rounding errors.
 *   - Detects singular matrices exactly (pivot = 0).
 *   - Uses standard Gaussian elimination with partial pivoting.
 *   - Cannot suffer from numerical instability in exact arithmetic.
 *
 * Use case:
 *   - Exact solutions, guaranteed singularity detection,
 *     symbolic or fractional arithmetic.
 *   - When you want standard LU without Bareiss fraction-free optimization.
 */

template<typename T>
class LUFactor {
public:
    using Scalar = T;
    using VectorType = Matrix<T>;

    LUFactor(const Matrix<T>& A) {
        compute(A);
    }

    // ------------------------------------------------------------------------
    // Perform standard LU factorization with partial pivoting
    // ------------------------------------------------------------------------
    void compute(const Matrix<T>& A) {
        const size_t n = A.rows();
        m_n = n;
        m_L = Matrix<T>::identity(n);
        m_U = A;
        m_P = Matrix<T>::identity(n);
        m_swap_count = 0;

        for (size_t k = 0; k < n - 1; ++k) {

            // ----- Partial Pivoting -----
            size_t max_row = k;
            T max_val = m_U(k, k);
            if (max_val < T(0)) max_val = -max_val;
            
            for (size_t i = k + 1; i < n; ++i) {
                T val = m_U(i, k);
                if (val < T(0)) val = -val;
                if (val > max_val) {
                    max_val = val;
                    max_row = i;
                }
            }
            
            if (max_row != k) {
                m_U.swap_rows(k, max_row);
                m_P.swap_rows(k, max_row);
                // L rows up to k-1 also swap to maintain LU decomposition
                if (k > 0) {
                    for (size_t j = 0; j < k; ++j) {
                        T tmp = m_L(k, j);
                        m_L(k, j) = m_L(max_row, j);
                        m_L(max_row, j) = tmp;
                    }
                }
                m_swap_count++;
            }
            
            const T pivot = m_U(k, k);
            if (pivot == T(0)) {
                m_is_singular = true;
                return;
            }

            // ----- Standard Gaussian Elimination Update -----
            for (size_t i = k + 1; i < n; ++i) {
                m_L(i, k) = m_U(i, k) / pivot;   // store multiplier

                for (size_t j = k + 1; j < n; ++j) {
                    m_U(i, j) = m_U(i, j) - m_L(i, k) * m_U(k, j);
                }
                m_U(i, k) = T(0);
            }
        }

        m_is_singular = (m_U(n - 1, n - 1) == T(0));
    }

    // ------------------------------------------------------------------------
    // Compute exact determinant
    // ------------------------------------------------------------------------
    T determinant() const {
        if (m_is_singular) return T(0);

        T det = T(1);

        // determinant(P) = sign of permutation = (-1)^(swap_count)
        if (m_swap_count % 2 == 1) det = T(-1);

        for (size_t i = 0; i < m_n; ++i)
            det *= m_U(i, i);

        return det;
    }

    // ------------------------------------------------------------------------
    // Compute inverse matrix via LU solve
    // ------------------------------------------------------------------------
    Matrix<T> inverse() const {
        Matrix<T> Inv(m_n, m_n);

        if (m_is_singular)
            throw std::runtime_error("Matrix is singular");

        for (size_t col = 0; col < m_n; ++col) {
            Matrix<T> e = Matrix<T>::Zero(m_n);
            e(col, 0) = T(1);
            Matrix<T> col_result = solve(e);
            // Copy column result into inverse
            for (size_t i = 0; i < m_n; ++i) {
                Inv(i, col) = col_result(i, 0);
            }
        }

        return Inv;
    }

    // ------------------------------------------------------------------------
    // Solve Ax = b using computed LU: A = P^T * L * U
    // ------------------------------------------------------------------------
    Matrix<T> solve(const Matrix<T>& b) const {
        // b must be a column vector
        if (b.cols() != 1 || b.rows() != m_n) {
            throw std::runtime_error("solve: b must be a column vector of size n");
        }
        
        // Apply permutation: bp = P * b
        Matrix<T> bp(m_n, 1);
        for (size_t i = 0; i < m_n; ++i) {
            T sum = T(0);
            for (size_t j = 0; j < m_n; ++j) {
                sum += m_P(i, j) * b(j, 0);
            }
            bp(i, 0) = sum;
        }
        
        Matrix<T> y(m_n, 1);
        Matrix<T> x(m_n, 1);

        // Forward substitution: L y = bp
        for (size_t i = 0; i < m_n; ++i) {
            T sum = bp(i, 0);
            for (size_t j = 0; j < i; ++j)
                sum -= m_L(i, j) * y(j, 0);
            y(i, 0) = sum;
        }

        // Back substitution: U x = y
        for (size_t i = m_n; i-- > 0; ) {
            T sum = y(i, 0);
            for (size_t j = i + 1; j < m_n; ++j)
                sum -= m_U(i, j) * x(j, 0);
            x(i, 0) = sum / m_U(i, i);
        }

        return x;
    }

    bool isSingular() const { return m_is_singular; }

private:
    size_t m_n;
    Matrix<T> m_L, m_U, m_P;
    bool m_is_singular = false;
    int m_swap_count = 0;
};

} // namespace rational_linalg

#endif // RATIONAL_LINALG_LU_HPP


=== cpp/include/rational_linalg/matrix.hpp ===
#ifndef RATIONAL_LINALG_MATRIX_HPP
#define RATIONAL_LINALG_MATRIX_HPP

#include <rational_linalg/fraction.hpp>
#include <fracessa/bitset64.hpp>
#include <vector>
#include <cstring>
#include <sstream>
#include <string>
#include <type_traits>

namespace rational_linalg {

template<typename T>
class Matrix {
public:
    // Constructors
    inline Matrix() : rows_(0), cols_(0), data_() {}
    
    inline Matrix(size_t rows, size_t cols) : rows_(rows), cols_(cols), data_(rows * cols) {
        // data_ now contains exactly rows*cols elements, all default-initialized to 0
    }
    
    inline Matrix(const Matrix& other) : rows_(other.rows_), cols_(other.cols_), data_(other.data_) {}
    
    inline Matrix(Matrix&& other) noexcept : rows_(other.rows_), cols_(other.cols_), data_(std::move(other.data_)) {
        other.rows_ = 0;
        other.cols_ = 0;
    }
    
    inline Matrix& operator=(const Matrix& other) {
        rows_ = other.rows_;
        cols_ = other.cols_;
        data_ = other.data_;
        return *this;
    }
    
    inline Matrix& operator=(Matrix&& other) noexcept {
        rows_ = other.rows_;
        cols_ = other.cols_;
        data_ = std::move(other.data_);
        other.rows_ = 0;
        other.cols_ = 0;
        return *this;
    }

    // Accessors - NO bounds checking
    inline T& operator()(size_t i, size_t j) noexcept {
        return data_[i * cols_ + j];
    }
    
    inline const T& operator()(size_t i, size_t j) const noexcept {
        return data_[i * cols_ + j];
    }
    
    inline size_t rows() const noexcept { return rows_; }
    inline size_t cols() const noexcept { return cols_; }
    
    inline T* data() noexcept { return data_.data(); }
    inline const T* data() const noexcept { return data_.data(); }

    // Arithmetic operators
    // unused
    // inline Matrix operator+(const Matrix& other) const {
    //     Matrix result(rows_, cols_);
    //     const size_t n = rows_ * cols_;
    //     for (size_t i = 0; i < n; ++i) {
    //         result.data_[i] = data_[i] + other.data_[i];
    //     }
    //     return result;
    // }
    
    // unused
    // inline Matrix operator-(const Matrix& other) const {
    //     Matrix result(rows_, cols_);
    //     const size_t n = rows_ * cols_;
    //     for (size_t i = 0; i < n; ++i) {
    //         result.data_[i] = data_[i] - other.data_[i];
    //     }
    //     return result;
    // }
    
    inline Matrix operator*(const Matrix& other) const {
        Matrix result(rows_, other.cols_);
        for (size_t i = 0; i < rows_; ++i) {
            for (size_t j = 0; j < other.cols_; ++j) {
                T sum = T(0);
                for (size_t k = 0; k < cols_; ++k) {
                    sum += data_[i * cols_ + k] * other.data_[k * other.cols_ + j];
                }
                result.data_[i * result.cols_ + j] = sum;
            }
        }
        return result;
    }
    
    inline Matrix operator*(const T& scalar) const {
        Matrix result(rows_, cols_);
        const size_t n = rows_ * cols_;
        for (size_t i = 0; i < n; ++i) {
            result.data_[i] = data_[i] * scalar;
        }
        return result;
    }
    
    // unused
    // inline Matrix operator/(const T& scalar) const {
    //     Matrix result(rows_, cols_);
    //     const size_t n = rows_ * cols_;
    //     for (size_t i = 0; i < n; ++i) {
    //         result.data_[i] = data_[i] / scalar;
    //     }
    //     return result;
    // }
    
    inline Matrix& operator+=(const Matrix& other) {
        const size_t n = rows_ * cols_;
        for (size_t i = 0; i < n; ++i) {
            data_[i] += other.data_[i];
        }
        return *this;
    }
    
    // unused
    // inline Matrix& operator-=(const Matrix& other) {
    //     const size_t n = rows_ * cols_;
    //     for (size_t i = 0; i < n; ++i) {
    //         data_[i] -= other.data_[i];
    //     }
    //     return *this;
    // }
    
    // unused
    // inline Matrix& operator*=(const T& scalar) {
    //     const size_t n = rows_ * cols_;
    //     for (size_t i = 0; i < n; ++i) {
    //         data_[i] *= scalar;
    //     }
    //     return *this;
    // }
    
    // unused
    // inline Matrix& operator/=(const T& scalar) {
    //     const size_t n = rows_ * cols_;
    //     for (size_t i = 0; i < n; ++i) {
    //         data_[i] /= scalar;
    //     }
    //     return *this;
    // }

    // Comparison operators
    // unused
    // inline bool operator==(const Matrix& other) const {
    //     if (rows_ != other.rows_ || cols_ != other.cols_) return false;
    //     const size_t n = rows_ * cols_;
    //     for (size_t i = 0; i < n; ++i) {
    //         if (data_[i] != other.data_[i]) return false;
    //     }
    //     return true;
    // }
    
    // unused
    // inline bool operator!=(const Matrix& other) const {
    //     return !(*this == other);
    // }

    // Matrix operations
    inline Matrix transpose() const {
        Matrix result(cols_, rows_);
        for (size_t i = 0; i < rows_; ++i) {
            for (size_t j = 0; j < cols_; ++j) {
                result.data_[j * result.cols_ + i] = data_[i * cols_ + j];
            }
        }
        return result;
    }
    
    // unused
    // inline bool is_square() const {
    //     return rows_ == cols_;
    // }
    
    // Infinity norm: ||A||_inf = max_i(sum_j |A_ij|) - maximum absolute row sum
    inline T infinity_norm() const {
        if (rows_ == 0 || cols_ == 0) return T(0);
        
        T max_row_sum = T(0);
        
        for (size_t i = 0; i < rows_; ++i) {
            T row_sum = T(0);
            for (size_t j = 0; j < cols_; ++j) {
                T val = (*this)(i, j);
                // Compute absolute value: for double use std::abs, for fraction use abs()
                if constexpr (std::is_same_v<T, double>) {
                    row_sum += std::abs(val);
                } else if constexpr (std::is_same_v<T, fraction>) {
                    row_sum += val.abs();
                } 
            }
            if (row_sum > max_row_sum) {
                max_row_sum = row_sum;
            }
        }
        
        return max_row_sum;
    }
    
    // String representation for logging
    inline std::string to_log_string() const {
        std::ostringstream oss;
        for (size_t i = 0; i < rows_; ++i) {
            oss << "\t\t\t";  // Add tabs before each line
            for (size_t j = 0; j < cols_; ++j) {
                oss << (*this)(i, j) << ",";
            }
            if (i < rows_ - 1) {
                oss << std::endl;
            }
        }
        return oss.str();
    }
    
    // Check if all entries of a matrix are greater than zero
    inline bool all_entries_greater_zero() const noexcept {
        const size_t n = rows_ * cols_;
        const T* data = data_.data();
        for (size_t i = 0; i < n; ++i) {
            if (data[i] <= T(0)) {
                return false;
            }
        }
        return true;
    }
    
    // Check if matrix is positive definite
    // Uses LDLT decomposition for fraction type and Cholesky decomposition for double type
    bool is_positive_definite() const;
    
    // Convert Matrix to Matrix<double>
    // Only supports fraction type
    inline Matrix<double> to_double() const {
        static_assert(std::is_same_v<T, fraction>, "to_double() only supports fraction type");
        Matrix<double> result(rows_, cols_);
        const size_t n = rows_ * cols_;
        const T* src = data_.data();
        double* dst = result.data();
        for (size_t i = 0; i < n; ++i) {
            dst[i] = src[i].to_double();
        }
        return result;
    }
    
    // unused
    // inline T determinant() const {
    //     // Bareiss algorithm for determinant - optimized for small matrices
    //     if (rows_ != cols_) return T(0);
    //     if (rows_ == 0) return T(1);
    //     if (rows_ == 1) return data_[0];
    //     
    //     Matrix work = *this;
    //     T div_prev = T(1);
    //     int swap_count = 0;
    //     
    //     for (size_t k = 0; k < rows_ - 1; ++k) {
    //         // Partial pivoting
    //         size_t max_row = k;
    //         T max_val = work(k, k);
    //         if (max_val < T(0)) max_val = -max_val;
    //         
    //         for (size_t i = k + 1; i < rows_; ++i) {
    //             T val = work(i, k);
    //             if (val < T(0)) val = -val;
    //             if (val > max_val) {
    //                 max_val = val;
    //                 max_row = i;
    //             }
    //         }
    //         
    //         if (max_row != k) {
    //             // Swap rows
    //             for (size_t j = 0; j < cols_; ++j) {
    //                 T tmp = work(k, j);
    //                 work(k, j) = work(max_row, j);
    //                 work(max_row, j) = tmp;
    //             }
    //             ++swap_count;
    //         }
    //         
    //         const T pivot = work(k, k);
    //         if (pivot == T(0)) return T(0);
    //         
    //         // Bareiss update
    //         for (size_t i = k + 1; i < rows_; ++i) {
    //             for (size_t j = k + 1; j < cols_; ++j) {
    //                 work(i, j) = (work(i, j) * pivot - work(i, k) * work(k, j)) / div_prev;
    //             }
    //             work(i, k) = T(0);
    //         }
    //         
    //         div_prev = pivot;
    //     }
    //     
    //     T det = T(1);
    //     if (swap_count % 2 == 1) det = T(-1);
    //     
    //     for (size_t i = 0; i < rows_; ++i) {
    //         det *= work(i, i);
    //     }
    //     
    //     return det;
    // }
    
    // unused
    // inline Matrix inverse() const {
    //     // Gauss-Jordan elimination for inverse - assumes non-singular
    //     Matrix inv(rows_, cols_);
    //     
    //     // Initialize augmented matrix [A | I]
    //     Matrix aug(rows_, cols_ * 2);
    //     for (size_t i = 0; i < rows_; ++i) {
    //         for (size_t j = 0; j < cols_; ++j) {
    //             aug(i, j) = data_[i * cols_ + j];
    //         }
    //         for (size_t j = 0; j < cols_; ++j) {
    //             aug(i, cols_ + j) = (i == j) ? T(1) : T(0);
    //         }
    //     }
    //     
    //     // Forward elimination with partial pivoting
    //     for (size_t k = 0; k < rows_; ++k) {
    //         // Partial pivoting
    //         size_t max_row = k;
    //         T max_val = aug(k, k);
    //         if (max_val < T(0)) max_val = -max_val;
    //         
    //         for (size_t i = k + 1; i < rows_; ++i) {
    //             T val = aug(i, k);
    //             if (val < T(0)) val = -val;
    //             if (val > max_val) {
    //                 max_val = val;
    //                 max_row = i;
    //             }
    //         }
    //         
    //         if (max_row != k) {
    //             // Swap rows
    //             for (size_t j = 0; j < aug.cols_; ++j) {
    //                 T tmp = aug(k, j);
    //                 aug(k, j) = aug(max_row, j);
    //                 aug(max_row, j) = tmp;
    //             }
    //         }
    //         
    //         const T pivot = aug(k, k);
    //         
    //         // Normalize pivot row
    //         for (size_t j = k + 1; j < aug.cols_; ++j) {
    //             aug(k, j) = aug(k, j) / pivot;
    //         }
    //         aug(k, k) = T(1);
    //         
    //         // Eliminate column k
    //         for (size_t i = 0; i < rows_; ++i) {
    //             if (i == k) continue;
    //             const T factor = aug(i, k);
    //             for (size_t j = k + 1; j < aug.cols_; ++j) {
    //                 aug(i, j) = aug(i, j) - aug(k, j) * factor;
    //             }
    //             aug(i, k) = T(0);
    //         }
    //     }
    //     
    //     // Extract inverse from right half
    //     for (size_t i = 0; i < rows_; ++i) {
    //         for (size_t j = 0; j < cols_; ++j) {
    //             inv(i, j) = aug(i, cols_ + j);
    //         }
    //     }
    //     
    //     return inv;
    // }

    // Utility functions
    inline void swap_rows(size_t i, size_t j) {
        for (size_t k = 0; k < cols_; ++k) {
            T tmp = data_[i * cols_ + k];
            data_[i * cols_ + k] = data_[j * cols_ + k];
            data_[j * cols_ + k] = tmp;
        }
    }
    
    // Extract principal submatrix from matrix using bitset64 mask
    // Optimized: iterates only over set bits for efficiency
    inline Matrix<T> principal_submatrix(const bitset64& support) const {
        size_t support_size = bs64::count_set_bits(support);
        Matrix<T> submatrix(support_size, support_size);
        // Only iterate over SET bits for efficiency
        size_t row = 0;
        for (size_t i = bs64::find_pos_first_set_bit(support); i < 64; i = bs64::find_pos_next_set_bit(support, i)) {
            size_t col = 0;
            for (size_t j = bs64::find_pos_first_set_bit(support); j < 64; j = bs64::find_pos_next_set_bit(support, j)) {
                submatrix(row, col) = (*this)(i, j);
                ++col;
            }
            ++row;
        }
        return submatrix;
    }
    
    // unused
    // inline void swap_cols(size_t i, size_t j) {
    //     for (size_t k = 0; k < rows_; ++k) {
    //         T tmp = data_[k * cols_ + i];
    //         data_[k * cols_ + i] = data_[k * cols_ + j];
    //         data_[k * cols_ + j] = tmp;
    //     }
    // }
    
    static inline Matrix zero(size_t rows, size_t cols) {
        Matrix result(rows, cols);
        // Constructor already zero-initializes all elements
        return result;
    }
    
    static inline Matrix identity(size_t n) {
        Matrix result(n, n);
        // Constructor already zero-initializes all elements, only need to set diagonal
        for (size_t i = 0; i < n; ++i) {
            result(i, i) = T(1);
        }
        return result;
    }

    // Vector helper functions (for Matrix used as vector)
    // unused
    // // head() - return first n elements as column vector
    // inline Matrix head(size_t n) const {
    //     // Assume this is a column vector (cols_ == 1)
    //     Matrix result(n, 1);
    //     for (size_t i = 0; i < n && i < rows_; ++i) {
    //         result(i, 0) = data_[i * cols_];
    //     }
    //     return result;
    // }
    
    // unused
    // // sum() - sum all elements
    // inline T sum() const {
    //     T result = T(0);
    //     const size_t n = rows_ * cols_;
    //     for (size_t i = 0; i < n; ++i) {
    //         result += data_[i];
    //     }
    //     return result;
    // }
    
    // unused
    // // Static Ones() - create column vector of ones
    // static inline Matrix Ones(size_t n) {
    //     Matrix result(n, 1);
    //     for (size_t i = 0; i < n; ++i) {
    //         result(i, 0) = T(1);
    //     }
    //     return result;
    // }
    
    // Static Zero() - create zero column vector (already zero from constructor, but explicit)
    static inline Matrix Zero(size_t n) {
        Matrix result(n, 1);
        // Constructor already zero-initializes
        return result;
    }
    
    // unused
    // // Dot product (for column vectors)
    // inline T dot(const Matrix& other) const {
    //     // Assume both are column vectors (cols_ == 1)
    //     T result = T(0);
    //     const size_t n = (rows_ < other.rows_) ? rows_ : other.rows_;
    //     for (size_t i = 0; i < n; ++i) {
    //         result += data_[i * cols_] * other.data_[i * other.cols_];
    //     }
    //     return result;
    // }

private:
    size_t rows_;
    size_t cols_;
    std::vector<T> data_;
};



// Factory functions (used in main.cpp)
template<typename T>
inline Matrix<T> create_circular_symmetric(size_t n, const std::vector<T>& half_row) {
    Matrix<T> result(n, n);
    // Constructor already zero-initializes all elements
    
    // Build first row
    std::vector<T> first_row(n);
    first_row[0] = T(0);
    
    if (n % 2 == 0) {
        // Even n
        first_row[n / 2] = half_row[half_row.size() - 1];
        for (size_t i = 0; i < n / 2 - 1; ++i) {
            first_row[i + 1] = half_row[i];
            first_row[n - i - 1] = half_row[i];
        }
    } else {
        // Odd n
        for (size_t i = 0; i < n / 2; ++i) {
            first_row[i + 1] = half_row[i];
            first_row[n - i - 1] = half_row[i];
        }
    }
    
    // Create circular matrix from first_row
    for (size_t i = 0; i < n; ++i) {
        for (size_t j = 0; j < n; ++j) {
            result(i, j) = first_row[(j - i + n) % n];
        }
    }
    
    return result;
}

template<typename T>
inline Matrix<T> create_symmetric(size_t n, const std::vector<T>& upper_triangular) {
    Matrix<T> result(n, n);
    // Constructor already zero-initializes all elements
    
    size_t idx = 0;
    for (size_t i = 0; i < n; ++i) {
        for (size_t j = i; j < n; ++j) {
            T val = upper_triangular[idx];
            result(i, j) = val;
            result(j, i) = val;  // Make symmetric
            ++idx;
        }
    }
    
    return result;
}

} // namespace rational_linalg

// Include implementation header for is_positive_definite
#include <rational_linalg/positive_definite.hpp>

#endif // RATIONAL_LINALG_MATRIX_HPP


=== cpp/include/rational_linalg/positive_definite.hpp ===
#pragma once

#include <rational_linalg/matrix.hpp>
#include <rational_linalg/fraction.hpp>
#include <type_traits>
#include <cmath>
#include <limits>

namespace rational_linalg {

// Member function implementation for is_positive_definite
// Uses LDLT decomposition for fraction type and Cholesky decomposition for double type
template<typename T>
inline bool Matrix<T>::is_positive_definite() const {
    if constexpr (std::is_same_v<T, fraction>) {
        // LDLT decomposition for fractions
        size_t n = rows_;
        Matrix<T> D(n, n);
        Matrix<T> L(n, n);
        
        // Initialize L as identity
        for (size_t i = 0; i < n; ++i) {
            for (size_t j = 0; j < n; ++j) {
                L(i, j) = (i == j) ? T(1) : T(0);
            }
        }

        for (size_t i = 0; i < n; ++i) {
            for (size_t j = 0; j < i; ++j) {
                T aSum = T(0);
                for (size_t k = 0; k < j; ++k) {
                    aSum += L(i, k) * L(j, k) * D(k, k);
                }
                L(i, j) = (T(1) / D(j, j)) * ((*this)(i, j) - aSum);
            }
            T bSum = T(0);
            for (size_t k = 0; k < i; ++k) {
                bSum += L(i, k) * L(i, k) * D(k, k);
            }
            D(i, i) = (*this)(i, i) - bSum;
            if (D(i, i) <= T(0)) {
                return false;
            }
        }
        return true;
    } else if constexpr (std::is_same_v<T, double>) {
        // Cholesky decomposition for double matrices
        const size_t n = rows_;
        
        // Matrix must be square
        if (n != cols_) {
            return false;
        }
        
        // Initialize L as zero matrix
        Matrix<double> L = Matrix<double>::zero(n, n);
        
        // Tolerance for positive definiteness check
        // Use machine epsilon scaled by infinity norm for numerical stability
        const double tolerance = std::numeric_limits<double>::epsilon() * infinity_norm();
        
        for (size_t i = 0; i < n; ++i) {
            // Compute off-diagonal elements: L[i,j] for j < i
            for (size_t j = 0; j < i; ++j) {
                double sum = 0.0;
                for (size_t k = 0; k < j; ++k) {
                    sum += L(i, k) * L(j, k);
                }
                L(i, j) = (1.0 / L(j, j)) * ((*this)(i, j) - sum);
            }
            
            // Compute diagonal element: L[i,i]
            double sum = 0.0;
            for (size_t k = 0; k < i; ++k) {
                sum += L(i, k) * L(i, k);
            }
            double diagonal_value = (*this)(i, i) - sum;
            
            // Check if matrix is positive definite
            // Diagonal value must be positive (within tolerance)
            if (diagonal_value <= tolerance) {
                return false;
            }
            
            L(i, i) = std::sqrt(diagonal_value);
        }
        
        return true;
    }
} 
}// namespace rational_linalg


=== cpp/src/checkstab.cpp ===
#include <fracessa/fracessa.hpp>
#include <fracessa/bitset64.hpp>
#include <rational_linalg/copositivity.hpp>
#include <rational_linalg/matrix.hpp>
#include <iostream>

// check_stability function
void fracessa::check_stability()
{
    bitset64 bitsetm = bs64::lowest_set_bit_as_bit(candidate_.support); //get lowest set bit as bitfield
    bitset64 extended_support_reduced = bs64::subtract(candidate_.extended_support, bitsetm); //ext support without m
    size_t m = bs64::find_pos_first_set_bit(candidate_.support);
    size_t extended_support_size_reduced = candidate_.extended_support_size - 1;

    if (conf_with_log_) {
        logger_->info("Support: {}", bs64::to_bitstring(candidate_.support, dimension_));
        logger_->info("Support size: {}", bs64::count_set_bits(candidate_.support));
        logger_->info("Extended support: {}", bs64::to_bitstring(candidate_.extended_support, dimension_));
        logger_->info("Extended support size: {}", candidate_.extended_support_size);
        logger_->info("Extended support reduced: {}", bs64::to_bitstring(extended_support_reduced, dimension_));
        logger_->info("index m: {}", m);
    }

    if (extended_support_size_reduced == 0)
    {
        if (conf_with_log_)
            logger_->info("Reason: true_pure_ess");
        candidate_.stability = "T_pure_ess";
        candidate_.is_ess = true;
        return;
    }
    
    // Get Bee matrix as double and check positive definiteness (faster check first)
    auto& Bee_double = matrix_server_.get_bee_matrix<double>(extended_support_reduced, m);
    
    if (Bee_double.is_positive_definite()) {
        if (conf_with_log_)
            logger_->info("Reason: true_posdef_double");
        candidate_.stability = "T_pd_double";
        candidate_.is_ess = true;
        return;
    }
    
    // Get Bee matrix from MatrixServer (builds it internally)
    auto& Bee = matrix_server_.get_bee_matrix<fraction>(extended_support_reduced, m);

    if (conf_with_log_) {
        logger_->info("matrix bee:\n{}", Bee.to_log_string());
    }

    if (Bee.is_positive_definite()) {
        if (conf_with_log_)
            logger_->info("Reason: true_posdef_rational");
        candidate_.stability = "T_pd_rat";
        candidate_.is_ess = true;
        return;
    }

    bitset64 kay = bs64::subtract(candidate_.extended_support, candidate_.support); //extended_support without support
    size_t kay_size = bs64::count_set_bits(kay);

    if (conf_with_log_)
        logger_->info("kay: {}", bs64::to_bitstring(kay, dimension_));

    if (kay_size==0 || kay_size==1) {
        if (conf_with_log_)
            logger_->info("Reason: false_not_posdef_and_kay_0_1");
        candidate_.stability = "F_not_pd_kay_0_1";
        candidate_.is_ess = false;
        return;
    }
   
    // Optimized partial copositivity check (Bomze 1992, p. 321/322)
    const bitset64 jay = extended_support_reduced;
    const bitset64 jay_minus_kay = bs64::subtract(jay, kay);
    const size_t r = bs64::count_set_bits(jay_minus_kay);

    // Pre-allocate all vectors
    std::vector<bitset64> kay_vee(r + 1);
    std::vector<size_t> kay_vee_size(r + 1);
    std::vector<bitset64> jay_without_kay_vee(r + 1);
    std::vector<rational_linalg::Matrix<fraction>> bee_vee(r + 1);

    // Initialize v=0
    kay_vee[0] = jay;
    kay_vee_size[0] = extended_support_size_reduced;
    jay_without_kay_vee[0] = jay_minus_kay;
    bee_vee[0] = Bee;

    if (conf_with_log_) {
        logger_->info("Partial Copositivity Check:");
        logger_->info("v=0: kay_vee={}, size={}, jay\\kay={}, r={}",
                    bs64::to_bitstring(kay_vee[0], dimension_),
                    kay_vee_size[0],
                    bs64::to_bitstring(jay_without_kay_vee[0], dimension_),
                    r);
        logger_->info("bee_vee[0]:\n{}", bee_vee[0].to_log_string());
    }

    // Main loop
    for (size_t v = 1; v <= r; ++v) {
        // Get lowest set bit and its position
        const unsigned iv_pos = bs64::find_pos_first_set_bit(jay_without_kay_vee[v-1]);
        
        // Update sets
        jay_without_kay_vee[v] = bs64::subtract(jay_without_kay_vee[v-1], bs64::single_bit_at_pos(iv_pos));
        kay_vee[v] = bs64::subtract(kay_vee[v-1], bs64::single_bit_at_pos(iv_pos));
        kay_vee_size[v] = kay_vee_size[v-1] - 1;
        
        // OPTIMIZED: Calculate pivot position using popcount
        // Count set bits in kay_vee[v-1] that are BEFORE iv_pos
        const bitset64 bits_before_iv = bs64::bits_before_pos(kay_vee[v-1], iv_pos);
        const size_t pivot_pos = bs64::count_set_bits(bits_before_iv);
        
        if (conf_with_log_) {
            logger_->info("v={}: kay_vee={}, size={}, jay\\kay={}, iv_pos={}, pivot_pos={}",
                        v,
                        bs64::to_bitstring(kay_vee[v], dimension_),
                        kay_vee_size[v],
                        bs64::to_bitstring(jay_without_kay_vee[v], dimension_),
                        iv_pos,
                        pivot_pos);
        }
        
        // Check pivot element
        const fraction& pivot = bee_vee[v-1](pivot_pos, pivot_pos);
        if (pivot <= fraction(0)) {
            if (conf_with_log_) {
                logger_->info("Reason: false_not_partial_copositive (pivot={} at pos={})", pivot.to_string(), pivot_pos);
            }
            candidate_.stability = "F_not_part_copos";
            candidate_.is_ess = false;
            return;
        }
        
        // Allocate new matrix
        bee_vee[v] = rational_linalg::Matrix<fraction>(kay_vee_size[v], kay_vee_size[v]);
        // Equation (20) in Bomze 1992
        const size_t n_old = kay_vee_size[v-1];
        const auto& B_old = bee_vee[v-1];
        auto& B_new = bee_vee[v];
        
        // Process rows/columns, skipping pivot
        for (size_t i_old = 0, i_new = 0; i_old < n_old; ++i_old) {
            if (i_old == pivot_pos) continue;  // Skip pivot row            
            for (size_t j_old = 0, j_new = 0; j_old < n_old; ++j_old) {
                if (j_old == pivot_pos) continue;  // Skip pivot column               
                // Rank-1 update: B'[i,j] = pivot*B[i,j] - B[i,pivot]*B[pivot,j]
                B_new(i_new, j_new) = pivot * B_old(i_old, j_old) - B_old(i_old, pivot_pos) * B_old(pivot_pos, j_old);                
                ++j_new;
            }
            ++i_new;
        }
        
        if (conf_with_log_) {
            logger_->info("bee_vee[{}]:\n{}", v, bee_vee[v].to_log_string());
        }
    }    
    //copositivity check as in hadeler_1983
    if (conf_with_log_)
        logger_->info("Copositivity Check:");

    if (rational_linalg::isStrictlyCopositiveMemoized(bee_vee[r])) {
        if (conf_with_log_)
            logger_->info("Reason: true_copositive");
        candidate_.stability = "T_copos";
        candidate_.is_ess = true;
        return;
    } else {
        if (conf_with_log_)
            logger_->info("Reason: false_not_copositive");
        candidate_.stability = "F_not_copos";
        candidate_.is_ess = false;
        return;
    }
}

=== cpp/src/findeq.cpp ===
#include <fracessa/fracessa.hpp>
#include <fracessa/bitset64.hpp>
#include <rational_linalg/linear_solver.hpp>
#include <cstdlib>
#include <type_traits>

// Templated function for all types (double, fraction)
template<typename T>
bool fracessa::find_candidate(const bitset64& support, size_t support_size)
{
    const auto& game_matrix = matrix_server_.get_game_matrix<T>();

    // Use LinearSolver for all types
    // get_linear_system returns a reference to the matrix in MatrixServer
    auto& Ab = matrix_server_.get_linear_system<T>(support, support_size);
    
    // The optimized LinearSolver (GaussRational/GaussDouble) takes a reference
    // and modifies the matrix in-place for efficiency.
    rational_linalg::LinearSolver<T> solver(Ab);
    rational_linalg::Matrix<T> solution;
    bool solved = solver.solve(solution);
    
    if (!solved)
        return false;    

    // Build full solution vector from support by padding with zeros
    rational_linalg::Matrix<T> solution_full_n = rational_linalg::Matrix<T>(dimension_, 1);    
    size_t tracker = 0;
    for (size_t i = 0; i < dimension_; i++) {
        if (bs64::is_set_at_pos(support, i)) {
            solution_full_n(i, 0) = solution(tracker, 0);
            tracker += 1;
        } else 
            solution_full_n(i, 0) = T(0);
    }

    // Check (Ap)_i <= v for all rows i not in the support
    const T payoff = solution(support_size, 0);
    candidate_.extended_support = support; // reset/init extended support
    
    // Split logic completely for double vs fraction
    if constexpr (std::is_same_v<T, double>) {
        // --- FLOATING POINT FILTER PATH ---
        const double threshold = payoff + 1e-4 * dimension_; // huge margin to avoid false negatives
        
        for (size_t i = 0; i < dimension_; i++) {
            if (!bs64::is_set_at_pos(support, i)) { // Row not in the support
                double rowsum = 0.0;
                for (size_t j = 0; j < dimension_; j++) {
                    if (bs64::is_set_at_pos(support, j)) { // Column is in the support
                        rowsum += game_matrix(i,j) * solution_full_n(j, 0);
                    }
                }
                
                if (rowsum > threshold) 
                    return false;
            }
        }
    } else {
        // --- EXACT ARITHMETIC PATH ---
        for (size_t i = 0; i < dimension_; i++) {
            if (!bs64::is_set_at_pos(support, i)) { // Row not in the support
                T rowsum = T(0);
                for (size_t j = 0; j < dimension_; j++) {
                    if (bs64::is_set_at_pos(support, j)) { // Column is in the support
                        // Optimized FLINT arithmetic: rowsum += matrix(i,j) * solution(j)
                        fmpq_addmul(rowsum.data(), game_matrix(i,j).data(), solution_full_n(j, 0).data());
                    }
                }
                
                if (rowsum > payoff)
                    return false;
                
                // Only track extended support in the exact phase
                if (rowsum == payoff)
                    candidate_.extended_support = bs64::set_bit_at_pos(candidate_.extended_support, i);
            }
        }

        // Store candidate data (Only needed when we have the final exact candidate)
        candidate_.vector = solution_full_n;
        candidate_.payoff = payoff;
        candidate_.payoff_double = payoff.to_double();        
        candidate_.extended_support_size = bs64::count_set_bits(candidate_.extended_support);
    }
    
    return true;
}

// Explicit template instantiations
template bool fracessa::find_candidate<double>(const bitset64&, size_t);
template bool fracessa::find_candidate<fraction>(const bitset64&, size_t);
=== cpp/src/fracessa.cpp ===
#include <fracessa/fracessa.hpp>
#include <fracessa/bitset64.hpp>
#include <rational_linalg/matrix.hpp>
#include <exception>
#include <numeric>

fracessa::fracessa(const rational_linalg::Matrix<fraction>& matrix, bool is_cs, bool with_candidates, bool exact, bool full_support, bool with_log, int matrix_id)
    : matrix_server_(matrix)
    , dimension_(matrix.rows())
    , is_cs_(is_cs)
    , matrix_id_(matrix_id)
    , conf_with_candidates_(with_candidates)
    , conf_exact_(exact)
    , conf_full_support_(full_support)
    , conf_with_log_(with_log)
    , candidate_()
    , supports_(dimension_, is_cs_)
    , logger_()
{
    if (conf_with_candidates_)
        candidates_.reserve(250 * dimension_);

    if (conf_with_log_) {
        auto rotating_sink = std::make_shared<spdlog::sinks::rotating_file_sink_mt>(
            "log/fracessa.log", 20*1024*1024, 5);  // 20MB, 5 files
        logger_ = std::make_shared<spdlog::logger>("fracessa", rotating_sink);
        logger_->set_pattern("[%Y-%m-%d %H:%M:%S.%e] [%l] %v");
        logger_->set_level(spdlog::level::info);
        
        // Write empty line and 3 lines of asterisks and hash symbols as first lines in log
        logger_->info("");
        logger_->info("*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*");
        logger_->info("#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#");
        logger_->info("*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*");        
        // Write matrix_id as first line in log
        if (matrix_id >= 0) {
            logger_->info("matrix_id={}", matrix_id);
        }
        
        logger_->info("n={}", dimension_);
        logger_->info("game matrix:\n{}", matrix_server_.get_game_matrix<fraction>().to_log_string());
    }
        
    // Initialize supports
    supports_.initialize();

    if (conf_full_support_) {      
        // Search full support (dimension_)
        // BATCH: supports_to_remove_.clear();
        for (const auto& support : supports_.get_supports(dimension_)) {
            search_one_support(support, dimension_);
        }
        // BATCH: Batch remove all collected supersets
        // supports_.remove_supersets_batch(supports_to_remove_, dimension_);
        // supports_to_remove_.clear();
        if (ess_count_ > 0) 
            return;                
    }
    // Search all support sizes
    for (size_t i = 1; i <= (conf_full_support_ ? dimension_-1: dimension_) ; i++) {
        if (conf_with_log_)
            logger_->info("Searching support size {}:", i);

        // BATCH: supports_to_remove_.clear();
        const bool is_cs_and_coprime = is_cs_ && (std::gcd(i, dimension_) == 1);
        for (const auto& support : supports_.get_supports(i)) {
            search_one_support(support, i, is_cs_and_coprime);
        }
        // BATCH: Batch remove all collected supersets for this support size
        // supports_.remove_supersets_batch(supports_to_remove_, i);
        // supports_to_remove_.clear();
    }
}


void fracessa::search_one_support(const bitset64& support, size_t support_size, bool is_cs_and_coprime)
{
    if (!conf_exact_) 
            if (!find_candidate<double>(support, support_size))
                return;

    if (!find_candidate<fraction>(support, support_size))
            return;

    candidate_.support_size = support_size;
    candidate_.support = support;
    candidate_.candidate_id++;
    
    if (conf_with_log_)
        logger_->info("Found candidate! Check stability:");

    check_stability();

    if (candidate_.is_ess)
        ess_count_++;

    if (is_cs_and_coprime)
        candidate_.shift_reference = candidate_.candidate_id;
    else
        candidate_.shift_reference = 0;

    if (conf_with_candidates_)
        candidates_.push_back(candidate_);

    if (conf_with_log_) {
        logger_->info("{}", candidate::header());
        logger_->info("{}", candidate_.to_string());
    }
    // BATCH: Collect support for batch removal
    // supports_to_remove_.push_back(candidate_.support);
    // Remove all supersets for this support using Supports class
    supports_.remove_supersets(candidate_.support, support_size);

    if (is_cs_and_coprime) { //do the same for the n-1 more candidates we get for free because of the coprime property!

        for (size_t i = 0; i < dimension_ - 1; i++) {

            candidate_.support = bs64::rot_one_right(candidate_.support, dimension_);

            candidate_.candidate_id++;

            if (candidate_.is_ess)
                ess_count_++;

            if (conf_with_candidates_) {
                // Rotate vector: move first element to end
                fraction first = candidate_.vector(0, 0);
                size_t vec_size = candidate_.vector.rows();
                for (size_t j = 0; j < vec_size - 1; j++) {
                    candidate_.vector(j, 0) = candidate_.vector(j + 1, 0);
                }
                candidate_.vector(vec_size - 1, 0) = first;
                candidate_.extended_support = bs64::rot_one_right(candidate_.extended_support, dimension_);
                candidates_.push_back(candidate_);

                if (conf_with_log_) {
                    logger_->info("{}", candidate::header());
                    logger_->info("{}", candidate_.to_string());
                }
            }
            // BATCH: Collect shifted support for batch removal
            // supports_to_remove_.push_back(candidate_.support);
            // Remove all supersets for shifted support using Supports class
            supports_.remove_supersets(candidate_.support, support_size);
        }
    }
}


=== cpp/src/main.cpp ===
#include <iostream>
#include <vector>
#include <string>
#include <chrono>
#include <iomanip>
#include <cstdint>

#include <fracessa/fracessa.hpp>
#include <rational_linalg/matrix.hpp>
#include <argparse/argparse.hpp>

// Helper function to parse matrix string format: "n#values"
// Returns true on success, false on error
bool parse_matrix_string(const std::string& matrix_str, rational_linalg::Matrix<fraction>& A, bool& is_cs)
{
    // Parse CLI string format: "n#values" - optimized manual parsing
    const size_t hash_pos = matrix_str.find('#');
    if (hash_pos == std::string::npos || hash_pos == 0 || hash_pos == matrix_str.length() - 1) {
        std::cerr << "Error: String for the matrix does not include '#' as a separator between dimension and matrix!" << std::endl;
        return false;
    }
    
    // Check for multiple '#' characters
    if (matrix_str.find('#', hash_pos + 1) != std::string::npos) {
        std::cerr << "Error: Multiple '#' characters found in matrix string!" << std::endl;
        return false;
    }
    
    size_t n;
    try {
        n = std::stoull(matrix_str.substr(0, hash_pos));
    } catch (const std::exception& e) {
        std::cerr << "Error: The given dimension could not be converted into an integer number!" << std::endl;
        return false;
    }
    
    // Parse comma-separated values - optimized manual parsing
    const std::string& values_str = matrix_str.substr(hash_pos + 1);
    std::vector<fraction> rational_values;
    
    // Pre-allocate vector with estimated size (at least n/2 for circular symmetric)
    rational_values.reserve(n / 2);
    
    try {
        size_t start = 0;
        size_t comma_pos;
        
        while (start < values_str.length()) {
            comma_pos = values_str.find(',', start);
            if (comma_pos == std::string::npos) {
                comma_pos = values_str.length();
            }
            
            // Parse value: "numerator/denominator" or just "numerator"
            const size_t slash_pos = values_str.find('/', start);
            if (slash_pos != std::string::npos && slash_pos < comma_pos) {
                // Has denominator
                int64_t num = std::stoll(values_str.substr(start, slash_pos - start));
                int64_t den = std::stoll(values_str.substr(slash_pos + 1, comma_pos - slash_pos - 1));
                // Explicitly construct fraction to avoid ambiguity
                rational_values.push_back(fraction(static_cast<long>(num), static_cast<long>(den)));
            } else {
                // No denominator, treat as integer
                int64_t num = std::stoll(values_str.substr(start, comma_pos - start));
                // Explicitly construct fraction to avoid ambiguity
                rational_values.push_back(fraction(static_cast<long>(num), 1L));
            }
            
            start = comma_pos + 1;
        }
    } catch (const std::exception& e) {
        std::cerr << "Error: Could not convert matrix values to fraction numbers!" << std::endl;
        std::cerr << "  " << e.what() << std::endl;
        return false;
    }
    
    // Determine matrix type and create matrix
    const size_t expected_cs = n / 2;
    const size_t expected_sym = n * (n + 1) / 2;
    const size_t actual_size = rational_values.size();
    
    if (actual_size == expected_cs) {
        // Circular symmetric matrix
        // COMMENTED OUT - now using fraction only (FLINT fraction)
        A = rational_linalg::create_circular_symmetric<fraction>(n, rational_values);
        is_cs = true;
    } else if (actual_size == expected_sym) {
        // Symmetric matrix (upper triangular)
        // COMMENTED OUT - now using fraction only (FLINT fraction)
        A = rational_linalg::create_symmetric<fraction>(n, rational_values);
        is_cs = false;
    } else {
        std::cerr << "Error: The number of matrix-elements must either be floor(dimension/2) (for a circular symmetric matrix) or dimension*(dimension+1)/2 (for a symmetric matrix)!" << std::endl;
        std::cerr << "  Got " << actual_size << " values, but expected " << expected_cs << " (circular symmetric) or " << expected_sym << " (symmetric)." << std::endl;
        return false;
    }
    
    return true;
}

// Unsafe version: parses matrix string without any safety checks for maximum performance
// Assumes valid input format: "n#values" where values are comma-separated rationals
// COMMENTED OUT - now using fraction only (FLINT fraction)
void parse_matrix_string_unsafe(const std::string& matrix_str, rational_linalg::Matrix<fraction>& A, bool& is_cs)
{
    // Find '#' by direct iteration
    size_t hash_pos = 0;
    while (matrix_str[hash_pos] != '#') {
        ++hash_pos;
    }
    
    // Parse dimension n manually (no stoull, no substr)
    size_t n = 0;
    for (size_t i = 0; i < hash_pos; ++i) {
        n = n * 10 + (matrix_str[i] - '0');
    }
    
    // Pre-allocate vector with estimated size
    std::vector<fraction> rational_values;
    rational_values.reserve(n / 2);
    
    // Parse values by direct character iteration
    size_t pos = hash_pos + 1;
    const size_t len = matrix_str.length();
    
    while (pos < len) {
        // Parse numerator
        int64_t num = 0;
        bool num_negative = false;
        
        if (matrix_str[pos] == '-') {
            num_negative = true;
            ++pos;
        }
        
        while (pos < len && matrix_str[pos] != '/' && matrix_str[pos] != ',') {
            num = num * 10 + (matrix_str[pos] - '0');
            ++pos;
        }
        
        if (num_negative) {
            num = -num;
        }
        
        // Check if there's a denominator
        if (pos < len && matrix_str[pos] == '/') {
            ++pos; // skip '/'
            
            // Parse denominator
            int64_t den = 0;
            bool den_negative = false;
            
            if (matrix_str[pos] == '-') {
                den_negative = true;
                ++pos;
            }
            
            while (pos < len && matrix_str[pos] != ',') {
                den = den * 10 + (matrix_str[pos] - '0');
                ++pos;
            }
            
            if (den_negative) {
                den = -den;
            }
            
            // Explicitly construct fraction to avoid ambiguity
            rational_values.push_back(fraction(static_cast<long>(num), static_cast<long>(den)));
        } else {
            // No denominator, treat as integer
            // Explicitly construct fraction to avoid ambiguity
            rational_values.push_back(fraction(static_cast<long>(num), 1L));
        }
        
        // Skip comma if present
        if (pos < len && matrix_str[pos] == ',') {
            ++pos;
        }
    }
    
    // Determine matrix type and create matrix
    const size_t expected_cs = n / 2;
    const size_t actual_size = rational_values.size();
    
    if (actual_size == expected_cs) {
        // Circular symmetric matrix
        // COMMENTED OUT - now using fraction only (FLINT fraction)
        A = rational_linalg::create_circular_symmetric<fraction>(n, rational_values);
        is_cs = true;
    } else {
        // Symmetric matrix (upper triangular)
        // COMMENTED OUT - now using fraction only (FLINT fraction)
        A = rational_linalg::create_symmetric<fraction>(n, rational_values);
        is_cs = false;
    }
}

int main(int argc, char *argv[])
{
    argparse::ArgumentParser program("fracessa", "3.0.0");

    program.add_description("FRACESSA - Fractional ESS Analyzer - A solver for Standard Quadratic Problems");

    program.add_argument("-c", "--candidates")
        .help("include the found candidates for ESS/solutions in the output")
        .implicit_value(true)
        .default_value(false);

    program.add_argument("-l", "--log")
        .help("output a detailed log file named 'fracessa.log' in the directory of the program, for diagnostic of learning purposes only")
        .implicit_value(true)
        .default_value(false);

    program.add_argument("-e", "--exact")
        .help("only uses fraction numbers, for matrices with extreme differences in the input, is much much slower!")
        .implicit_value(true)
        .default_value(false);

    program.add_argument("-f", "--fullsupport")
        .help("searches the full support directly after searching support size one. Enable if you expect the matrix to have exactly one ess in the interior of the simplex!")
        .implicit_value(true)
        .default_value(false);

    program.add_argument("-t", "--timing")
        .help("output the computation time in seconds on a new line after the ESS count")
        .implicit_value(true)
        .default_value(false);

    program.add_argument("-m", "--matrixid")
        .help("optional matrix ID to write in the log file")
        .scan<'i', int>()
        .default_value(-1);

    program.add_argument("-u", "--unsafe")
        .help("use unsafe matrix string parsing for maximum performance (no input validation)")
        .implicit_value(true)
        .default_value(false);

    program.add_argument("matrix")
        .help("the matrix to compute");

    try {
        program.parse_args(argc, argv);
    }
    catch (const std::runtime_error& err) {
        std::cerr << err.what() << std::endl;
        std::cerr << program;
        return EXIT_FAILURE;
    }

    const auto& matrix_str = program.get<std::string>("matrix");
    const auto candidates = program.get<bool>("--candidates");
    const auto logger = program.get<bool>("--log");
    const auto exact = program.get<bool>("--exact");
    const auto fullsupport = program.get<bool>("--fullsupport");
    const auto timing = program.get<bool>("--timing");
    const auto matrix_id = program.get<int>("--matrixid");
    const auto unsafe = program.get<bool>("--unsafe");

    // Parse matrix from CLI string format: "n#values"
    bool is_cs;
    // COMMENTED OUT - now using fraction only (FLINT fraction)
    rational_linalg::Matrix<fraction> A;
    if (unsafe) {
        parse_matrix_string_unsafe(matrix_str, A, is_cs);
    } else {
        if (!parse_matrix_string(matrix_str, A, is_cs)) {
            return EXIT_FAILURE;
        }
    }
    
    // Measure computation time only if timing flag is set
    std::chrono::high_resolution_clock::time_point start_time, end_time;
    double elapsed_seconds = 0.0;
    
    if (timing) {
        start_time = std::chrono::high_resolution_clock::now();
    }
    
    ::fracessa x(A, is_cs, candidates, exact, fullsupport, logger, matrix_id);
    
    if (timing) {
        end_time = std::chrono::high_resolution_clock::now();
        // Calculate elapsed time in seconds
        const auto duration = std::chrono::duration_cast<std::chrono::microseconds>(end_time - start_time);
        elapsed_seconds = duration.count() / 1000000.0;
    }

    std::cout << x.ess_count_ << std::endl;
    
    // Output timing on second line if -t flag is present
    if (timing) {
        std::cout << std::fixed << std::setprecision(6) << elapsed_seconds << std::endl;
    }

    if (candidates) {
        std::cout << candidate::header() << std::endl;
        for (auto& c : x.candidates_) {
            std::cout << c.to_string() << std::endl;
        }
    }

    return EXIT_SUCCESS;
}
